{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbc3421-5ad4-4445-bdb8-001db667b842",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <a id=\"table-of-contents\"></a>Table of Contents\n",
    "\n",
    "1. [Portfolio_marginal_attributes](#portfolio_marginal_attributes)\n",
    "2. [Portfolio_attributes](#portfolio_attributes)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe810a4-6a80-4dbc-809a-ea8daa73e804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import trim_mean\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746d5b24-ce76-4457-aeff-a966bf8fb1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL INPUTS\n",
    "\n",
    "#List portfolio securities here:\n",
    "portfolio_with_candidate = [\"SPY_history.csv\", \"XLU_history.csv\", \"XLF_history.csv\"]\n",
    "portfolio_without_candidate= [\"XLF_history.csv\",\"SPY_history.csv\"]\n",
    "candidate = [\"XLU_history.csv\"]\n",
    "\n",
    "# Define weights_with_candidate (make sure the keys match the column names):\n",
    "weights_with_candidate = {\n",
    "    'Return_SPY': 0.3,  # 50% weight to SPY\n",
    "    'Return_XLU': 0.5,  # 30% weight to XLU\n",
    "    'Return_XLF': 0.2   # 20% weight to XLF\n",
    "}\n",
    "\n",
    "observations_to_keep= 1500"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c3b8e73-a757-452a-a451-478142db479e",
   "metadata": {},
   "source": [
    "REMOVE DEPENDENCIES ON WEIGHTS IN ALL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e79b64-65a3-4994-9f2c-7496e359c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_portfolio_data(securities):\n",
    "    # Define the Data folder path\n",
    "    data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "    \n",
    "    # Initialize an empty list to store the DataFrames\n",
    "    data_frames = []\n",
    "    \n",
    "    # Iterate over the list of security files\n",
    "    for file_name in securities:\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Convert 'Date' column to datetime format\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        \n",
    "        # Extract security name from file name (e.g., \"SPY\" from \"SPY_history.csv\")\n",
    "        security_name = file_name.split('_')[0]\n",
    "        \n",
    "        # Rename columns to include security name\n",
    "        data = data.add_suffix(f'_{security_name}')\n",
    "        \n",
    "        # Calculate day-over-day price change based on 'Close' column\n",
    "        data[f'Return_{security_name}'] = data[f'Close/Last_{security_name}'].pct_change()\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        data_frames.append(data)\n",
    "    \n",
    "    # Combine all CSV side by side\n",
    "    combined_data = pd.concat(data_frames, axis=1)\n",
    "    \n",
    "    # Calculate the portfolio's daily return (average of all securities' daily returns)\n",
    "    return_columns = [col for col in combined_data.columns if col.startswith(\"Return_\")]\n",
    "    combined_data[\"portfolio_daily_return\"] = combined_data[return_columns].mean(axis=1)\n",
    "      \n",
    "    # Add Original_Index column to capture current index\n",
    "    combined_data['Original_Index'] = combined_data.index\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0d11c3-392c-448a-9f4b-a6224ce27a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data for different portfolios\n",
    "portfolio_with_candidate_df = process_portfolio_data(portfolio_with_candidate)\n",
    "portfolio_without_candidate_df = process_portfolio_data(portfolio_without_candidate)\n",
    "candidate_df = process_portfolio_data(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7acfe0b6-55fe-42bb-aad1-ff2f4ba4cfac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Close/Last_SPY', 'Volume_SPY', 'Open_SPY', 'High_SPY',\n",
       "       'Low_SPY', 'Return_SPY', 'Close/Last_XLU', 'Volume_XLU', 'Open_XLU',\n",
       "       'High_XLU', 'Low_XLU', 'Return_XLU', 'Close/Last_XLF', 'Volume_XLF',\n",
       "       'Open_XLF', 'High_XLF', 'Low_XLF', 'Return_XLF', 'Original_Index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_with_candidate_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e32894-6afe-44c8-8b7d-f85eac4e45eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add function to sort DataFrame by Original_Index\n",
    "def sort_by_original_index(data):\n",
    "    return data.sort_values(by='Original_Index', ascending=False)\n",
    "\n",
    "# Sort the DataFrames by Original_Index\n",
    "portfolio_with_candidate = sort_by_original_index(portfolio_with_candidate_df)\n",
    "portfolio_without_candidate = sort_by_original_index(portfolio_without_candidate_df)\n",
    "candidate = sort_by_original_index(candidate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5cef4-e186-4e9e-b987-8ec3d021a7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Alternative approach (modifying in place if desired, be cautious with this!):\n",
    "def drop_indices_in_place(df):\n",
    "  if len(df) > observations_to_keep:\n",
    "      df.drop(index=df.index[:observations_to_keep], axis=0, inplace=True)  # Efficient for large DataFrames\n",
    "      df.reset_index(drop=True, inplace=True) # Reset index after dropping\n",
    "\n",
    "# Example of in-place usage:\n",
    "drop_indices_in_place(portfolio_with_candidate)\n",
    "drop_indices_in_place(portfolio_without_candidate)\n",
    "drop_indices_in_place(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e8e6b41-876e-4445-94dc-f0c1d771ec14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'portfolio_with_candidate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mportfolio_with_candidate\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'portfolio_with_candidate' is not defined"
     ]
    }
   ],
   "source": [
    "portfolio_with_candidate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07fdc36-9323-4046-90fa-295fd55009c0",
   "metadata": {},
   "source": [
    "## Portfolio_marginal_attributes <a id=\"portfolio_marginal_attributes\"></a>\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c02ca1f-6458-4b1a-99f7-7f1172a286e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_weighted_metrics(df, weights):\n",
    "    \n",
    "    # Filter weights to only include columns that exist in the subset of securities (df.columns)\n",
    "    valid_weights = {col: weight for col, weight in weights.items() if col in df.columns}\n",
    "    \n",
    "    # Normalize the weights to ensure the total weight equals 1\n",
    "    total_weight = sum(valid_weights.values())\n",
    "    normalized_weights = {col: weight / total_weight for col, weight in valid_weights.items()}\n",
    "\n",
    "    # Initialize weighted skewness and kurtosis\n",
    "    weighted_skew = 0\n",
    "    weighted_kurtosis = 0\n",
    "\n",
    "    # Loop through each valid column and calculate skewness and kurtosis\n",
    "    for column_name, weight in normalized_weights.items():\n",
    "        data = df[column_name].dropna()  # Drop NaNs from the column\n",
    "        \n",
    "        # Calculate individual skewness and kurtosis\n",
    "        skewness = skew(data)\n",
    "        kurt = kurtosis(data)\n",
    "\n",
    "        # Apply weights to the metrics\n",
    "        weighted_skew += skewness * weight\n",
    "        weighted_kurtosis += kurt * weight\n",
    "\n",
    "    return {\n",
    "        'portfolio_weighted_skew': weighted_skew,\n",
    "        'portfolio_weighted_kurtosis': weighted_kurtosis,\n",
    "        'normalized_weights': normalized_weights  # Return updated weights for the subset\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a485ec5-7b9b-472c-ae23-f8dce7346fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'portfolio_weighted_skew': 0.8085280874340329, 'portfolio_weighted_kurtosis': 15.627860449017438, 'normalized_weights': {'Return_SPY': 0.3, 'Return_XLU': 0.5, 'Return_XLF': 0.2}}\n",
      "{'portfolio_weighted_skew': 1.0093302801348536, 'portfolio_weighted_kurtosis': 15.530671908266383, 'normalized_weights': {'Return_SPY': 0.6, 'Return_XLF': 0.4}}\n",
      "{'portfolio_weighted_skew': 0.6077258947332123, 'portfolio_weighted_kurtosis': 15.725048989768496, 'normalized_weights': {'Return_XLU': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "print(calculate_weighted_metrics(portfolio_with_candidate_df, weights_with_candidate)) \n",
    "print(calculate_weighted_metrics(portfolio_without_candidate_df, weights_with_candidate)) \n",
    "print(calculate_weighted_metrics(candidate_df, weights_with_candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a5e7fd-5249-41b0-805d-4f763e45804a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_kurtosis_skew_overlay(df1, df2, df3, column_name, labels):\n",
    "    \"\"\"\n",
    "    Calculates kurtosis and skew for three DataFrames and overlays their histograms.\n",
    "\n",
    "    Args:\n",
    "        df1, df2, df3 (pd.DataFrame): The three DataFrames to compare.\n",
    "        column_name (str): The column name to analyze and plot.\n",
    "        labels (list): A list of three labels corresponding to the DataFrames. dfdf\n",
    " \n",
    "    Returns:\n",
    "        dict: A dictionary with kurtosis and skew for all three DataFrames.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Calculate kurtosis and skew for all three DataFrames\n",
    "    try:\n",
    "        for df, label in zip([df1, df2, df3], labels):\n",
    "            if column_name in df.columns:\n",
    "                data = df[column_name].dropna()\n",
    "                if len(data) < 2:\n",
    "                    print(f\"Warning: Not enough data in '{column_name}' for {label}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Calculate kurtosis and skew\n",
    "                k = kurtosis(data)\n",
    "                s = skew(data)\n",
    "\n",
    "                results[label] = {'kurtosis': k, 'skew': s}\n",
    "            else:\n",
    "                print(f\"Warning: '{column_name}' not found in {label}. Skipping.\")\n",
    "\n",
    "        # Plot overlapping histograms\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for df, label, color in zip([df1, df2, df3], labels, ['skyblue', 'lightcoral', 'lightgreen']):\n",
    "            if column_name in df.columns:\n",
    "                data = df[column_name].dropna()\n",
    "                plt.hist(data, bins=40, alpha=0.5, label=f\"{label}\", color=color, edgecolor='black', linewidth=1.0)\n",
    "\n",
    "        plt.title(f'Distribution of {column_name}')\n",
    "        plt.xlabel(column_name)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c764a5f-ae24-4350-af9f-eb71684aa02e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'portfolio_with_candidate_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract portfolio daily returns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m returns_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith Candidate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mportfolio_with_candidate_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mportfolio_daily_return\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna(),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithout Candidate\u001b[39m\u001b[38;5;124m\"\u001b[39m: portfolio_without_candidate_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mportfolio_daily_return\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna(),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate Only\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mportfolio_daily_return\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute Statistics\u001b[39;00m\n\u001b[1;32m      9\u001b[0m stats \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     label: {\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean(data),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label, data \u001b[38;5;129;01min\u001b[39;00m returns_data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     17\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'portfolio_with_candidate_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract portfolio daily returns\n",
    "returns_data = {\n",
    "    \"With Candidate\": portfolio_with_candidate_df[\"portfolio_daily_return\"].dropna(),\n",
    "    \"Without Candidate\": portfolio_without_candidate_df[\"portfolio_daily_return\"].dropna(),\n",
    "    \"Candidate Only\": candidate_df[\"portfolio_daily_return\"].dropna()\n",
    "}\n",
    "\n",
    "# Compute Statistics\n",
    "stats = {\n",
    "    label: {\n",
    "        \"Mean\": np.mean(data),\n",
    "        \"Std Dev\": np.std(data),\n",
    "        \"Kurtosis\": kurtosis(data),\n",
    "        \"Skew\": skew(data)\n",
    "    }\n",
    "    for label, data in returns_data.items()\n",
    "}\n",
    "\n",
    "# Plot Overlayed Histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = [\"blue\", \"green\", \"red\"]\n",
    "\n",
    "for (label, data), color in zip(returns_data.items(), colors):\n",
    "    sns.histplot(data, bins=50, kde=True, color=color, label=f\"{label}\\n\"\n",
    "        f\"Mean: {stats[label]['Mean']:.4f}\\n\"\n",
    "        f\"Std Dev: {stats[label]['Std Dev']:.4f}\\n\"\n",
    "        f\"Kurtosis: {stats[label]['Kurtosis']:.4f}\\n\"\n",
    "        f\"Skew: {stats[label]['Skew']:.4f}\"\n",
    "    , alpha=0.4)\n",
    "\n",
    "# Customize Plot\n",
    "plt.legend(fontsize=10)\n",
    "plt.title(\"Portfolio Daily Return Distributions\")\n",
    "plt.xlabel(\"Daily Return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f32c63a-d741-4962-8513-13253b084f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trimmed_std_dev(data, trim_percent=0.02):\n",
    "    \"\"\"\n",
    "    Calculate the trimmed standard deviation for a portfolio's average daily return.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing daily returns of all securities\n",
    "    - trim_percent (float): Percentage of observations to trim from each end (default 10%)\n",
    "\n",
    "    Returns:\n",
    "    - float: Trimmed standard deviation of the portfolio\n",
    "    \"\"\"\n",
    "    # Select only return columns (avoid including other numerical data)\n",
    "    return_columns = [col for col in data.columns if col.startswith(\"Return_\")]\n",
    "    if not return_columns:\n",
    "        raise ValueError(\"No return columns found in the dataset!\")\n",
    "\n",
    "    # Compute the portfolio's daily return (average of all securities' daily returns)\n",
    "    data[\"portfolio_daily_return\"] = data[return_columns].mean(axis=1)\n",
    "\n",
    "    # Extract the portfolio daily returns as a series\n",
    "    portfolio_returns = data[\"portfolio_daily_return\"].dropna().values\n",
    "\n",
    "    # Trim the extreme observations\n",
    "    trim_count = int(len(portfolio_returns) * trim_percent)\n",
    "    sorted_returns = np.sort(portfolio_returns)\n",
    "    trimmed_returns = sorted_returns[trim_count:-trim_count]  # Trim bottom & top values\n",
    "\n",
    "    # Compute and return standard deviation of the trimmed dataset\n",
    "    return np.std(trimmed_returns, ddof=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f6fa6f-7d8e-4297-972a-f82018a24103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'portfolio_without_candidate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compute trimmed standard deviations\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trimmed_std_portfolio_without_candidate \u001b[38;5;241m=\u001b[39m trimmed_std_dev(\u001b[43mportfolio_without_candidate\u001b[49m, trim_percent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m)\n\u001b[1;32m      3\u001b[0m trimmed_std_portfolio_with_candidate \u001b[38;5;241m=\u001b[39m trimmed_std_dev(portfolio_with_candidate, trim_percent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m)\n\u001b[1;32m      4\u001b[0m trimmed_std_candidate \u001b[38;5;241m=\u001b[39m trimmed_std_dev(candidate, trim_percent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'portfolio_without_candidate' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute trimmed standard deviations\n",
    "trimmed_std_portfolio_without_candidate = trimmed_std_dev(portfolio_without_candidate, trim_percent=0.02)\n",
    "trimmed_std_portfolio_with_candidate = trimmed_std_dev(portfolio_with_candidate, trim_percent=0.02)\n",
    "trimmed_std_candidate = trimmed_std_dev(candidate, trim_percent=0.02)\n",
    "\n",
    "# Print results\n",
    "print(\"Trimmed Std Dev (Portfolio without Candidate):\", trimmed_std_portfolio_without_candidate)\n",
    "print(\"Trimmed Std Dev (Candidate Security):\", trimmed_std_candidate)\n",
    "print(\"Trimmed Std Dev (Portfolio with Candidate):\", trimmed_std_portfolio_with_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd344087-7377-4f38-a36d-034d8055c877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_mean_difference(data, column):\n",
    "    \"\"\"\n",
    "    Calculate the Gini mean difference for a specified column in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame containing the data.\n",
    "        column (str): The column name for which to calculate the Gini mean difference.\n",
    "        \n",
    "    Returns:\n",
    "        float: The Gini mean difference.\n",
    "    \"\"\"\n",
    "    # Extract the specified column values\n",
    "    values = data[column].dropna().values\n",
    "    \n",
    "    # Calculate the absolute differences between all pairs of elements\n",
    "    diff_matrix = np.abs(np.subtract.outer(values, values))\n",
    "    \n",
    "    # Calculate the mean of the absolute differences\n",
    "    gini_mean_diff = np.mean(diff_matrix)\n",
    "    \n",
    "    return gini_mean_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e05d77-931a-4c84-9de3-a3db4e0480aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'portfolio_with_candidate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gini_portfolio_with_candidate \u001b[38;5;241m=\u001b[39m gini_mean_difference(\u001b[43mportfolio_with_candidate\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportfolio_daily_return\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m gini_portfolio_without_candidate \u001b[38;5;241m=\u001b[39m gini_mean_difference(portfolio_without_candidate, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportfolio_daily_return\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m gini_candidate \u001b[38;5;241m=\u001b[39m gini_mean_difference(candidate, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportfolio_daily_return\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'portfolio_with_candidate' is not defined"
     ]
    }
   ],
   "source": [
    "gini_portfolio_with_candidate = gini_mean_difference(portfolio_with_candidate, 'portfolio_daily_return')\n",
    "gini_portfolio_without_candidate = gini_mean_difference(portfolio_without_candidate, 'portfolio_daily_return')\n",
    "gini_candidate = gini_mean_difference(candidate, 'portfolio_daily_return')\n",
    "\n",
    "print(f'Gini Mean Difference (without candidate): {gini_portfolio_without_candidate}')\n",
    "print(f'Gini Mean Difference (candidate): {gini_candidate}')\n",
    "print(f'Gini Mean Difference (with candidate): {gini_portfolio_with_candidate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a3c34-cb41-4fa5-9e7d-64a89a3fa51f",
   "metadata": {},
   "source": [
    "DOUBLE CHECK THE STATIONARITY OF GINI MEAN COEFFICENT AND TRIMMED STANDARD DEVIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3f7aeb-2bcc-49e4-bfec-5fc2bc164842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gini_portfolio_with_candidate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Define the calculated values\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m gini_values \u001b[38;5;241m=\u001b[39m [\u001b[43mgini_portfolio_with_candidate\u001b[49m, gini_portfolio_without_candidate, gini_candidate]\n\u001b[1;32m     46\u001b[0m trimmed_std_values \u001b[38;5;241m=\u001b[39m [trimmed_std_portfolio_with_candidate, trimmed_std_portfolio_without_candidate, trimmed_std_candidate]\n\u001b[1;32m     47\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith Candidate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWithout Candidate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate Only\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gini_portfolio_with_candidate' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_clustered_bar_chart_with_labels(gini_values, trimmed_std_values, labels):\n",
    "    \"\"\"\n",
    "    Plots a clustered bar chart with value labels for Gini mean difference\n",
    "    and trimmed standard deviation for three portfolios.\n",
    "\n",
    "    Args:\n",
    "        gini_values (list): A list of Gini mean differences for the portfolios.\n",
    "        trimmed_std_values (list): A list of trimmed standard deviations for the portfolios.\n",
    "        labels (list): A list of labels for the portfolios.\n",
    "    \"\"\"\n",
    "    # Number of portfolios\n",
    "    n_portfolios = len(labels)\n",
    "\n",
    "    # Bar positions\n",
    "    x = np.arange(n_portfolios)  # X-axis positions for the groups\n",
    "    bar_width = 0.35  # Width of each bar\n",
    "\n",
    "    # Plot bars\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    gini_bars = plt.bar(x - bar_width / 2, gini_values, width=bar_width, label='Gini Mean Difference', color='skyblue')\n",
    "    std_bars = plt.bar(x + bar_width / 2, trimmed_std_values, width=bar_width, label='Trimmed Std Dev', color='lightcoral')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title('Comparison of Portfolio Statistics')\n",
    "    plt.xlabel('Portfolios')\n",
    "    plt.ylabel('Values')\n",
    "    plt.xticks(x, labels)  # Set portfolio labels for x-axis ticks\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # Add value labels to the bars\n",
    "    for bar in gini_bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    for bar in std_bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height, f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the calculated values\n",
    "gini_values = [gini_portfolio_with_candidate, gini_portfolio_without_candidate, gini_candidate]\n",
    "trimmed_std_values = [trimmed_std_portfolio_with_candidate, trimmed_std_portfolio_without_candidate, trimmed_std_candidate]\n",
    "labels = [\"With Candidate\", \"Without Candidate\", \"Candidate Only\"]\n",
    "\n",
    "# Call the function to plot the bar chart\n",
    "plot_clustered_bar_chart_with_labels(gini_values, trimmed_std_values, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fb35d-d136-454e-9d56-44b0d3e34b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Portfolio_attributes <a id=\"portfolio_attributes\"></a>\n",
    "\n",
    "[Back to Table of Contents](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981bfd51-81da-42da-8fc2-d04933265b1b",
   "metadata": {},
   "source": [
    "Shape of the Distribution (Skewness, Kurtosis, Standard Deviation, Mean):\n",
    "Since you're working with returns, which are essentially first-differenced prices, you're correct that they've already been detrended to some extent. This makes the assumption of mean-variance stationarity less critical.\n",
    "\n",
    "Even though financial returns can still exhibit non-stationary behavior (e.g., volatility clustering), their distributional properties (like skewness and kurtosis) are relatively stable over time if calculated over a large enough sample.\n",
    "\n",
    "In this case, you don't necessarily need to account for stationarity explicitly unless your analysis spans vastly different market conditions (like a bull market vs. a bear market).\n",
    "\n",
    "You're absolutely right that for metrics like beta and covariance, which depend on relationships between securities, stationarity is more crucial. If the underlying data isn't stationary, these metrics could fluctuate unpredictably over time, making them unreliable.\n",
    "\n",
    "\n",
    "You're absolutely correct that if your focus is on the stability of variance, covariance, and beta, the concept of mean stationarity isn't particularly relevant.Don't use dickey-fuller or ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc161c7-ac90-48a5-aae2-b1f4e2a01604",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'portfolio_with_candidate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Select only the \"Close/Last_\" columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m close_columns \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[43mportfolio_with_candidate\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose/Last_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate daily percentage returns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m returns \u001b[38;5;241m=\u001b[39m portfolio_with_candidate[close_columns]\u001b[38;5;241m.\u001b[39mpct_change()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'portfolio_with_candidate' is not defined"
     ]
    }
   ],
   "source": [
    "# Select only the \"Close/Last_\" columns\n",
    "close_columns = [col for col in portfolio_with_candidate.columns if col.startswith('Close/Last_')]\n",
    "\n",
    "# Calculate daily percentage returns\n",
    "returns = portfolio_with_candidate[close_columns].pct_change()\n",
    "\n",
    "# Drop NaN values (from the first row caused by pct_change)\n",
    "returns = returns.dropna()\n",
    "\n",
    "# 1. Correlation Matrix\n",
    "correlation_matrix = returns.corr()\n",
    "\n",
    "# 2. Covariance Matrix\n",
    "covariance_matrix = returns.cov()\n",
    "\n",
    "# 3. Beta Matrix - Adjust to have the same shape as correlation and covariance matrices\n",
    "benchmark = close_columns[0]\n",
    "betas = {}\n",
    "\n",
    "# Initialize beta_matrix with NaN values to match the size of the correlation and covariance matrices\n",
    "beta_matrix = pd.DataFrame(np.nan, index=close_columns, columns=close_columns)\n",
    "\n",
    "for col in close_columns:\n",
    "    for row in close_columns:\n",
    "        if col == row:\n",
    "            beta_matrix.loc[row, col] = 1\n",
    "        else:\n",
    "            beta = covariance_matrix.loc[col, benchmark] / covariance_matrix.loc[benchmark, benchmark] \n",
    "            beta_matrix.loc[col, benchmark] = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27ffb56-cecf-481a-8488-a03536f3211c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'covariance_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m covariance_conversion_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e6\u001b[39m  \u001b[38;5;66;03m# Adjust this based on what \"mu\" represents\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply conversion factor to covariance matrix\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m covariance_matrix_mu \u001b[38;5;241m=\u001b[39m \u001b[43mcovariance_matrix\u001b[49m \u001b[38;5;241m*\u001b[39m covariance_conversion_factor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Store matrices in a dictionary for dynamic plotting\u001b[39;00m\n\u001b[1;32m      8\u001b[0m matrices \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: correlation_matrix,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCovariance Matrix (mu)\u001b[39m\u001b[38;5;124m\"\u001b[39m: covariance_matrix_mu,  \u001b[38;5;66;03m# Use converted covariance matrix\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBeta Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m: beta_matrix\n\u001b[1;32m     12\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'covariance_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a conversion factor for covariance (e.g., multiplying by 1e6 for 'mu' units)\n",
    "covariance_conversion_factor = 1e6  # Adjust this based on what \"mu\" represents\n",
    "\n",
    "# Apply conversion factor to covariance matrix\n",
    "covariance_matrix_mu = covariance_matrix * covariance_conversion_factor\n",
    "\n",
    "# Store matrices in a dictionary for dynamic plotting\n",
    "matrices = {\n",
    "    \"Correlation Matrix\": correlation_matrix,\n",
    "    \"Covariance Matrix (mu)\": covariance_matrix_mu,  # Use converted covariance matrix\n",
    "    \"Beta Matrix\": beta_matrix\n",
    "}\n",
    "\n",
    "num_matrices = len(matrices)  # Adjust based on how many matrices you have\n",
    "\n",
    "# Create subplots dynamically\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=num_matrices,  \n",
    "    subplot_titles=list(matrices.keys()),  # Dynamically set titles\n",
    "    column_widths=[1/num_matrices] * num_matrices,  \n",
    "    shared_yaxes=True,\n",
    "    shared_xaxes=True\n",
    ")\n",
    "\n",
    "# Adjust x positions for colorbars below each heatmap, adding some spacing\n",
    "x_positions = np.linspace(0.15, 0.85, num_matrices)  # Spread them evenly from left to right with spacing\n",
    "\n",
    "# Add each matrix as a heatmap dynamically\n",
    "for i, (title, matrix) in enumerate(matrices.items(), start=1):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=matrix.values,\n",
    "            x=matrix.columns,\n",
    "            y=matrix.columns,\n",
    "            colorscale=\"RdBu\",\n",
    "            colorbar=dict(\n",
    "                title=title.split()[0],  # Use first word of title (Correlation, Covariance, Beta)\n",
    "                tickvals=[matrix.values.min(), 0, matrix.values.max()],\n",
    "                yanchor=\"top\",\n",
    "                y=-0.25,  # Move colorbar slightly below the heatmap\n",
    "                x=x_positions[i - 1],  # Align it under each respective heatmap with spacing\n",
    "                xanchor=\"center\",\n",
    "                orientation=\"v\"  # Make the colorbar vertical\n",
    "            ),\n",
    "            text=matrix.values.round(2),\n",
    "            texttemplate=\"%{text}\",\n",
    "            showscale=True,\n",
    "            hoverinfo=\"skip\"\n",
    "        ),\n",
    "        row=1, col=i\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Correlation, Covariance (mu), and Beta Matrices\",\n",
    "    height=750,  # Increased height to accommodate vertical legends\n",
    "    showlegend=False,\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Show the interactive heatmap\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddceb16-6216-4271-bf90-09c513fab6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a64a9-6499-4706-9e47-c6ebcec221ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c5347-cf31-4be6-ad60-4c588b21f5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
