{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9ed79e-112a-418f-b955-5c13dd46dd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from pygam import LinearGAM, s\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2982057a-32e3-43e6-b761-6240815efa25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from CSV cache...\n",
      "(503, 8)\n",
      "Index(['symbol', 'name', 'sector', 'subSector', 'headQuarter',\n",
      "       'dateFirstAdded', 'cik', 'founded'],\n",
      "      dtype='object')\n",
      "  symbol                  name                  sector  \\\n",
      "0    XYZ           Block, Inc.              Technology   \n",
      "1    TTD  The Trade Desk, Inc.              Technology   \n",
      "2   DDOG               Datadog              Technology   \n",
      "3   COIN       Coinbase Global      Financial Services   \n",
      "4   DASH              DoorDash  Communication Services   \n",
      "\n",
      "                            subSector              headQuarter dateFirstAdded  \\\n",
      "0           Software - Infrastructure      Oakland, California     2025-07-23   \n",
      "1              Software - Application      Ventura, California     2025-07-18   \n",
      "2              Software - Application  New York City, New York     2025-07-09   \n",
      "3  Financial - Data & Stock Exchanges     Wilmington, Delaware     2025-05-19   \n",
      "4      Internet Content & Information        San Francisco, CA     2025-03-24   \n",
      "\n",
      "       cik founded  \n",
      "0  1512673    2009  \n",
      "1  1671933    2009  \n",
      "2  1561550    2010  \n",
      "3  1679788    2012  \n",
      "4  1792789    2013  \n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# --- LOAD FROM CACHE OR FETCH ---\n",
    "if os.path.exists(tickers_csv_file):\n",
    "    print(\"Loading tickers from CSV cache...\")\n",
    "    df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "else:\n",
    "    print(\"Fetching tickers from API...\")\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}\"\n",
    "    df_sp500 = pd.DataFrame(requests.get(url).json())\n",
    "\n",
    "    # Save to CSV\n",
    "    df_sp500.to_csv(tickers_csv_file, index=False)\n",
    "    print(f\"Saved {len(df_sp500)} tickers to CSV cache.\")\n",
    "\n",
    "    \n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()\n",
    "# --- PREVIEW ---\n",
    "print(df_sp500.shape)\n",
    "print(df_sp500.columns)\n",
    "print(df_sp500.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7840d0-3280-4f6b-8164-3d1996487ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/price_and_earnings.json\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# Load tickers\n",
    "df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()\n",
    "\n",
    "# Output file\n",
    "output_file = os.path.join(data_folder, \"price_and_earnings.json\")\n",
    "\n",
    "def fetch_price_and_earnings(tickers, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        return pd.DataFrame(json.load(open(output_file)))\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Get current price\n",
    "            quote_url = f\"https://financialmodelingprep.com/api/v3/quote/{ticker}?apikey={API_KEY}\"\n",
    "            price_data = requests.get(quote_url).json()\n",
    "            if not price_data:\n",
    "                continue\n",
    "            price = price_data[0][\"price\"]\n",
    "\n",
    "            # Get latest annual income statement (EPS or netIncome)\n",
    "            income_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=1&apikey={API_KEY}\"\n",
    "            income_data = requests.get(income_url).json()\n",
    "            if not income_data:\n",
    "                continue\n",
    "            eps = income_data[0].get(\"eps\")\n",
    "            net_income = income_data[0].get(\"netIncome\")\n",
    "\n",
    "            records.append({\n",
    "                \"symbol\": ticker,\n",
    "                \"price\": price,\n",
    "                \"eps\": eps,\n",
    "                \"netIncome\": net_income\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(0.2)  # polite rate limit\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "price_earnings_df = fetch_price_and_earnings(tickers, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb737c07-dc25-4514-858c-f5178907b5be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows used: 480\n",
      "0    2.741115\n",
      "1    4.033134\n",
      "2    5.514162\n",
      "3    3.434049\n",
      "4    6.756855\n",
      "Name: log_PE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Only keep rows with positive EPS\n",
    "pe_data = price_earnings_df[price_earnings_df[\"eps\"] > 0].copy()\n",
    "\n",
    "# Compute log(PE)\n",
    "pe_data[\"log_PE\"] = np.log(pe_data[\"price\"] / pe_data[\"eps\"])\n",
    "\n",
    "# Optional: store just the series if you want\n",
    "pe_series = pe_data[\"log_PE\"]\n",
    "\n",
    "# Print row count for reference\n",
    "print(f\"Rows used: {len(pe_series)}\")\n",
    "print(pe_series.head())\n",
    "\n",
    "# we are only pulling the eps and takingthe log here.. the code that follows doesn't immediately and directly build on this code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031400b-6a30-4ff6-ab53-72963cfe5a96",
   "metadata": {},
   "source": [
    "## break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1844560d-77dc-4f2a-8993-96bb263662be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/income-statement_annual_limit2.json\n",
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/balance-sheet-statement_annual_limit2.json\n",
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/cash-flow-statement_annual_limit2.json\n",
      "Income shape: (1006, 38)\n",
      "Balance shape: (1006, 54)\n",
      "Cash flow shape: (1006, 40)\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'revenue', 'costOfRevenue',\n",
      "       'grossProfit', 'grossProfitRatio', 'researchAndDevelopmentExpenses',\n",
      "       'generalAndAdministrativeExpenses', 'sellingAndMarketingExpenses',\n",
      "       'sellingGeneralAndAdministrativeExpenses', 'otherExpenses',\n",
      "       'operatingExpenses', 'costAndExpenses', 'interestIncome',\n",
      "       'interestExpense', 'depreciationAndAmortization', 'ebitda',\n",
      "       'ebitdaratio', 'operatingIncome', 'operatingIncomeRatio',\n",
      "       'totalOtherIncomeExpensesNet', 'incomeBeforeTax',\n",
      "       'incomeBeforeTaxRatio', 'incomeTaxExpense', 'netIncome',\n",
      "       'netIncomeRatio', 'eps', 'epsdiluted', 'weightedAverageShsOut',\n",
      "       'weightedAverageShsOutDil', 'link', 'finalLink'],\n",
      "      dtype='object')\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'cashAndCashEquivalents',\n",
      "       'shortTermInvestments', 'cashAndShortTermInvestments', 'netReceivables',\n",
      "       'inventory', 'otherCurrentAssets', 'totalCurrentAssets',\n",
      "       'propertyPlantEquipmentNet', 'goodwill', 'intangibleAssets',\n",
      "       'goodwillAndIntangibleAssets', 'longTermInvestments', 'taxAssets',\n",
      "       'otherNonCurrentAssets', 'totalNonCurrentAssets', 'otherAssets',\n",
      "       'totalAssets', 'accountPayables', 'shortTermDebt', 'taxPayables',\n",
      "       'deferredRevenue', 'otherCurrentLiabilities', 'totalCurrentLiabilities',\n",
      "       'longTermDebt', 'deferredRevenueNonCurrent',\n",
      "       'deferredTaxLiabilitiesNonCurrent', 'otherNonCurrentLiabilities',\n",
      "       'totalNonCurrentLiabilities', 'otherLiabilities',\n",
      "       'capitalLeaseObligations', 'totalLiabilities', 'preferredStock',\n",
      "       'commonStock', 'retainedEarnings',\n",
      "       'accumulatedOtherComprehensiveIncomeLoss',\n",
      "       'othertotalStockholdersEquity', 'totalStockholdersEquity',\n",
      "       'totalEquity', 'totalLiabilitiesAndStockholdersEquity',\n",
      "       'minorityInterest', 'totalLiabilitiesAndTotalEquity',\n",
      "       'totalInvestments', 'totalDebt', 'netDebt', 'link', 'finalLink'],\n",
      "      dtype='object')\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'netIncome',\n",
      "       'depreciationAndAmortization', 'deferredIncomeTax',\n",
      "       'stockBasedCompensation', 'changeInWorkingCapital',\n",
      "       'accountsReceivables', 'inventory', 'accountsPayables',\n",
      "       'otherWorkingCapital', 'otherNonCashItems',\n",
      "       'netCashProvidedByOperatingActivities',\n",
      "       'investmentsInPropertyPlantAndEquipment', 'acquisitionsNet',\n",
      "       'purchasesOfInvestments', 'salesMaturitiesOfInvestments',\n",
      "       'otherInvestingActivites', 'netCashUsedForInvestingActivites',\n",
      "       'debtRepayment', 'commonStockIssued', 'commonStockRepurchased',\n",
      "       'dividendsPaid', 'otherFinancingActivites',\n",
      "       'netCashUsedProvidedByFinancingActivities',\n",
      "       'effectOfForexChangesOnCash', 'netChangeInCash', 'cashAtEndOfPeriod',\n",
      "       'cashAtBeginningOfPeriod', 'operatingCashFlow', 'capitalExpenditure',\n",
      "       'freeCashFlow', 'link', 'finalLink'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def fetch_statement(endpoint, tickers, period, limit, data_folder):\n",
    "    \"\"\"Fetch statements with unique JSON filename based on endpoint, period, limit.\"\"\"\n",
    "    output_file = os.path.join(\n",
    "        data_folder,\n",
    "        f\"{endpoint}_{period}_limit{limit}.json\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        with open(output_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/{endpoint}/{ticker}?period={period}&limit={limit}&apikey={API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                for row in data:\n",
    "                    row[\"symbol\"] = ticker\n",
    "                records.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker} ({endpoint}): {e}\")\n",
    "        time.sleep(.2)  # API polite rate limit\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "income_data_2_years   = fetch_statement(\"income-statement\", tickers, \"annual\", 2, data_folder)\n",
    "balance_data_2_years  = fetch_statement(\"balance-sheet-statement\", tickers, \"annual\", 2, data_folder)\n",
    "cashflow_data_2_years = fetch_statement(\"cash-flow-statement\", tickers, \"annual\", 2, data_folder)\n",
    "\n",
    "# Convert to DataFrames\n",
    "income_data_2_years   = pd.DataFrame(income_data_2_years)\n",
    "balance_data_2_years  = pd.DataFrame(balance_data_2_years)\n",
    "cashflow_data_2_years = pd.DataFrame(cashflow_data_2_years)\n",
    "\n",
    "print(\"Income shape:\", income_data_2_years.shape)\n",
    "print(\"Balance shape:\", balance_data_2_years.shape)\n",
    "print(\"Cash flow shape:\", cashflow_data_2_years.shape)\n",
    "\n",
    "print(income_data_2_years.columns)\n",
    "print(balance_data_2_years.columns)\n",
    "print(cashflow_data_2_years.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6e9e1d-7967-4d9d-bedd-c234025a3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_symbol_date(df):\n",
    "    return df.sort_values([\"symbol\", \"date\"])\n",
    "\n",
    "\n",
    "def compute_yoy_growth(df, exclude_cols=[\"symbol\", \"date\",\"link\",\"finalLink\"]):\n",
    "    numeric_cols = df.select_dtypes(include=[float, int]).columns\n",
    "    numeric_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "    \n",
    "    df_growth = df.copy()\n",
    "    for col in numeric_cols:\n",
    "        df_growth[col + \"_yoy\"] = df.groupby(\"symbol\")[col].pct_change()\n",
    "    \n",
    "    return df_growth\n",
    "\n",
    "\n",
    "income_sorted = sort_by_symbol_date(income_data_2_years)\n",
    "balance_sorted = sort_by_symbol_date(balance_data_2_years)\n",
    "cashflow_sorted = sort_by_symbol_date(cashflow_data_2_years)\n",
    "\n",
    "income_growth = compute_yoy_growth(income_sorted)\n",
    "balance_growth = compute_yoy_growth(balance_sorted)\n",
    "cashflow_growth = compute_yoy_growth(cashflow_sorted)\n",
    "\n",
    "\n",
    "#we are sorting to make sure that hte dates are properly aligned before we perform out pct chagne method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3379f-f655-4b95-bf6e-9eef3d845b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130f17b0-b137-4386-b95c-58b08ed4a839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income 0/NaN counts per YoY column:\n",
      "                                             zeros  nans\n",
      "revenue_yoy                                      0   503\n",
      "grossProfit_yoy                                  0   503\n",
      "costAndExpenses_yoy                              0   503\n",
      "ebitdaratio_yoy                                  0   503\n",
      "operatingIncome_yoy                              0   503\n",
      "operatingIncomeRatio_yoy                         0   503\n",
      "incomeBeforeTax_yoy                              0   503\n",
      "incomeBeforeTaxRatio_yoy                         0   503\n",
      "netIncomeRatio_yoy                               0   503\n",
      "ebitda_yoy                                       0   504\n",
      "operatingExpenses_yoy                            0   507\n",
      "costOfRevenue_yoy                                0   510\n",
      "totalOtherIncomeExpensesNet_yoy                  0   535\n",
      "generalAndAdministrativeExpenses_yoy             0   756\n",
      "netIncome_yoy                                    1   503\n",
      "eps_yoy                                          1   503\n",
      "epsdiluted_yoy                                   1   503\n",
      "depreciationAndAmortization_yoy                  1   508\n",
      "incomeTaxExpense_yoy                             1   508\n",
      "sellingGeneralAndAdministrativeExpenses_yoy      1   530\n",
      "otherExpenses_yoy                                1   642\n",
      "researchAndDevelopmentExpenses_yoy               1   792\n",
      "sellingAndMarketingExpenses_yoy                  3   841\n",
      "interestIncome_yoy                               4   667\n",
      "weightedAverageShsOut_yoy                        7   503\n",
      "grossProfitRatio_yoy                             9   503\n",
      "weightedAverageShsOutDil_yoy                     9   503\n",
      "interestExpense_yoy                              9   530\n",
      "\n",
      "Balance 0/NaN counts per YoY column:\n",
      "                                             zeros  nans\n",
      "otherNonCurrentAssets_yoy                        0   503\n",
      "totalAssets_yoy                                  0   503\n",
      "totalLiabilities_yoy                             0   503\n",
      "totalStockholdersEquity_yoy                      0   503\n",
      "totalEquity_yoy                                  0   503\n",
      "totalLiabilitiesAndStockholdersEquity_yoy        0   503\n",
      "totalLiabilitiesAndTotalEquity_yoy               0   503\n",
      "totalNonCurrentAssets_yoy                        0   504\n",
      "totalCurrentAssets_yoy                           0   505\n",
      "longTermDebt_yoy                                 0   505\n",
      "totalNonCurrentLiabilities_yoy                   0   505\n",
      "retainedEarnings_yoy                             0   505\n",
      "otherNonCurrentLiabilities_yoy                   0   508\n",
      "netReceivables_yoy                               0   513\n",
      "accountPayables_yoy                              0   530\n",
      "shortTermInvestments_yoy                         0   780\n",
      "otherAssets_yoy                                  0   971\n",
      "otherLiabilities_yoy                             0   985\n",
      "cashAndCashEquivalents_yoy                       1   503\n",
      "cashAndShortTermInvestments_yoy                  1   503\n",
      "totalDebt_yoy                                    1   504\n",
      "totalCurrentLiabilities_yoy                      1   508\n",
      "otherCurrentLiabilities_yoy                      1   510\n",
      "propertyPlantEquipmentNet_yoy                    1   511\n",
      "otherCurrentAssets_yoy                           1   536\n",
      "othertotalStockholdersEquity_yoy                 1   547\n",
      "totalInvestments_yoy                             1   602\n",
      "longTermInvestments_yoy                          1   658\n",
      "deferredTaxLiabilitiesNonCurrent_yoy             1   665\n",
      "taxPayables_yoy                                  1   674\n",
      "deferredRevenue_yoy                              1   731\n",
      "netDebt_yoy                                      2   503\n",
      "capitalLeaseObligations_yoy                      2   605\n",
      "taxAssets_yoy                                    2   752\n",
      "inventory_yoy                                    3   666\n",
      "deferredRevenueNonCurrent_yoy                    3   869\n",
      "accumulatedOtherComprehensiveIncomeLoss_yoy      5   515\n",
      "intangibleAssets_yoy                             5   586\n",
      "shortTermDebt_yoy                                6   539\n",
      "minorityInterest_yoy                            13   719\n",
      "goodwillAndIntangibleAssets_yoy                 24   539\n",
      "preferredStock_yoy                              27   949\n",
      "goodwill_yoy                                    73   553\n",
      "commonStock_yoy                                244   534\n",
      "\n",
      "Cashflow 0/NaN counts per YoY column:\n",
      "                                              zeros  nans\n",
      "netCashProvidedByOperatingActivities_yoy          0   503\n",
      "netCashUsedForInvestingActivites_yoy              0   503\n",
      "netCashUsedProvidedByFinancingActivities_yoy      0   503\n",
      "cashAtBeginningOfPeriod_yoy                       0   503\n",
      "operatingCashFlow_yoy                             0   503\n",
      "freeCashFlow_yoy                                  0   503\n",
      "otherWorkingCapital_yoy                           0   506\n",
      "investmentsInPropertyPlantAndEquipment_yoy        0   529\n",
      "deferredIncomeTax_yoy                             0   567\n",
      "effectOfForexChangesOnCash_yoy                    0   636\n",
      "inventory_yoy                                     0   660\n",
      "purchasesOfInvestments_yoy                        0   672\n",
      "commonStockIssued_yoy                             0   791\n",
      "netIncome_yoy                                     1   503\n",
      "netChangeInCash_yoy                               1   503\n",
      "cashAtEndOfPeriod_yoy                             1   503\n",
      "depreciationAndAmortization_yoy                   1   507\n",
      "capitalExpenditure_yoy                            1   527\n",
      "accountsReceivables_yoy                           1   561\n",
      "accountsPayables_yoy                              1   574\n",
      "acquisitionsNet_yoy                               1   618\n",
      "salesMaturitiesOfInvestments_yoy                  1   665\n",
      "changeInWorkingCapital_yoy                        2   503\n",
      "otherNonCashItems_yoy                             2   504\n",
      "debtRepayment_yoy                                 2   536\n",
      "dividendsPaid_yoy                                 2   597\n",
      "otherFinancingActivites_yoy                       3   511\n",
      "otherInvestingActivites_yoy                       5   532\n",
      "stockBasedCompensation_yoy                        5   580\n",
      "commonStockRepurchased_yoy                        8   568\n"
     ]
    }
   ],
   "source": [
    "def count_zeros_nans_yoy(df):\n",
    "    # Keep only numeric columns that end with \"_yoy\"\n",
    "    numeric_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c.endswith(\"_yoy\")]\n",
    "    \n",
    "    # Count zeros and NaNs\n",
    "    zero_counts = (df[numeric_cols] == 0).sum()\n",
    "    nan_counts = df[numeric_cols].isna().sum()\n",
    "    \n",
    "    # Combine into a single DataFrame\n",
    "    summary = pd.DataFrame({\n",
    "        \"zeros\": zero_counts,\n",
    "        \"nans\": nan_counts\n",
    "    }).sort_values(by=[\"zeros\", \"nans\"], ascending=True)\n",
    "    \n",
    "    # Force full display\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "        print(summary)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "print(\"Income 0/NaN counts per YoY column:\")\n",
    "income_summary = count_zeros_nans_yoy(income_growth)\n",
    "\n",
    "print(\"\\nBalance 0/NaN counts per YoY column:\")\n",
    "balance_summary = count_zeros_nans_yoy(balance_growth)\n",
    "\n",
    "print(\"\\nCashflow 0/NaN counts per YoY column:\")\n",
    "cashflow_summary = count_zeros_nans_yoy(cashflow_growth)\n",
    "\n",
    "# the purpose here is to make it easy to identify which line items (columns) are fully filled out from our sample so that we are only grabbing columns (features)\n",
    "# that are likely to be filled out by the stock under consideration, cause ultimately after we find a regression that has explanatory power... we can still only apply it \n",
    "# to the stock under consideration if it has the same line items filled out \n",
    "# the 503 nans is a result of the .pct change method that we used which creates a nan on every other row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676f2825-768b-4ae3-bb05-0fba40fcac2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income cleaned shape: (502, 17)\n",
      "Balance cleaned shape: (502, 12)\n",
      "Cashflow cleaned shape: (501, 12)\n"
     ]
    }
   ],
   "source": [
    "def remove_single_period_features(df, nan_threshold=503, keep_cols=[\"symbol\",\"date\"], name=\"\"):\n",
    "    \"\"\"Select _yoy numeric columns, replace inf, drop rows/columns with too many NaNs.\"\"\"\n",
    "    yoy_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c.endswith(\"_yoy\")]\n",
    "    sub_df = df[yoy_cols + keep_cols].copy()  # Keep symbol/date columns\n",
    "    \n",
    "    # Drop columns with too many NaNs (only apply to yoy columns)\n",
    "    valid_yoy_cols = [c for c in yoy_cols if sub_df[c].isna().sum() <= nan_threshold]\n",
    "    sub_df = sub_df[valid_yoy_cols + keep_cols]\n",
    "    \n",
    "    # Replace infinities with NaN and drop rows with any remaining NaNs (only apply to yoy columns)\n",
    "    sub_df[valid_yoy_cols] = sub_df[valid_yoy_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    sub_df.dropna(subset=valid_yoy_cols, inplace=True)\n",
    "    \n",
    "    print(f\"{name} cleaned shape: {sub_df.shape}\")\n",
    "    return sub_df\n",
    "\n",
    "# Step 0: Clean _yoy columns and print shapes\n",
    "income_clean = remove_single_period_features(income_growth, name=\"Income\")\n",
    "balance_clean = remove_single_period_features(balance_growth, name=\"Balance\")\n",
    "cashflow_clean = remove_single_period_features(cashflow_growth, name=\"Cashflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f7de5d-cb6c-4ffb-90d8-21e3ee14d871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Keep only common (symbol, date) pairs\n",
    "for df in [income_clean, balance_clean, cashflow_clean]:\n",
    "    df[\"symbol_date\"] = list(zip(df[\"symbol\"], df[\"date\"]))\n",
    "\n",
    "common_pairs = (\n",
    "    set(income_clean[\"symbol_date\"])\n",
    "    & set(balance_clean[\"symbol_date\"])\n",
    "    & set(cashflow_clean[\"symbol_date\"])\n",
    ")\n",
    "\n",
    "income_clean = income_clean[income_clean[\"symbol_date\"].isin(common_pairs)].copy()\n",
    "balance_clean = balance_clean[balance_clean[\"symbol_date\"].isin(common_pairs)].copy()\n",
    "cashflow_clean = cashflow_clean[cashflow_clean[\"symbol_date\"].isin(common_pairs)].copy()\n",
    "\n",
    "# we only want to include a ticker if we have all the financial statement items for all three financial statements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45ff5cc-0343-463b-a89d-32c3f8b744a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and aligned shapes: (491, 18) (491, 13) (491, 13)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Sort consistently\n",
    "income_clean = income_clean.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "balance_clean = balance_clean.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "cashflow_clean = cashflow_clean.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Cleaned and aligned shapes:\", income_clean.shape, balance_clean.shape, cashflow_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47abcfd7-fcfc-44ee-bf39-194b62583559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Clean & align by (symbol, date)\n",
    "def clean_and_align(dfs, nan_threshold=503, keep_cols=[\"symbol\",\"date\"]):\n",
    "    \"\"\"\n",
    "    1) Drop columns with too many NaNs\n",
    "    2) Replace inf with NaN\n",
    "    3) Drop rows with any remaining NaNs\n",
    "    4) Align multiple DataFrames by shared (symbol, date) rows\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    for name, df in dfs.items():\n",
    "        # Select _yoy numeric columns\n",
    "        yoy_cols = [c for c in df.select_dtypes(include=[float,int]).columns if c.endswith(\"_yoy\")]\n",
    "        # Keep only valid columns under nan_threshold\n",
    "        valid_cols = [c for c in yoy_cols if df[c].isna().sum() <= nan_threshold]\n",
    "        sub_df = df[valid_cols + keep_cols].copy()\n",
    "        \n",
    "        # Replace infs with NaN and drop rows with any remaining NaNs\n",
    "        sub_df[valid_cols] = sub_df[valid_cols].replace([np.inf, -np.inf], np.nan)\n",
    "        before = sub_df.shape[0]\n",
    "        sub_df.dropna(subset=valid_cols, inplace=True)\n",
    "        after = sub_df.shape[0]\n",
    "        print(f\"{name}: {before - after} rows dropped due to NaNs\")\n",
    "        \n",
    "        # Create composite key\n",
    "        sub_df[\"symbol_date\"] = list(zip(sub_df[\"symbol\"], sub_df[\"date\"]))\n",
    "        cleaned[name] = sub_df\n",
    "        print(f\"{name} shape after cleaning: {sub_df.shape}\")\n",
    "    \n",
    "    # Find shared (symbol, date) across all dfs\n",
    "    common_pairs = set.intersection(*(set(df[\"symbol_date\"]) for df in cleaned.values()))\n",
    "    print(f\"Shared (symbol, date) rows across all dfs: {len(common_pairs)}\")\n",
    "    \n",
    "    # Filter each df to shared rows\n",
    "    aligned = {name: df[df[\"symbol_date\"].isin(common_pairs)].copy().reset_index(drop=True) \n",
    "               for name, df in cleaned.items()}\n",
    "    \n",
    "    # Drop helper column\n",
    "    for df in aligned.values():\n",
    "        df.drop(columns=[\"symbol_date\"], inplace=True)\n",
    "    \n",
    "    return aligned, common_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae15f3d-85b7-4b9c-8dc4-9e2495ffa557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income: 0 rows dropped due to NaNs\n",
      "income shape after cleaning: (491, 18)\n",
      "balance: 0 rows dropped due to NaNs\n",
      "balance shape after cleaning: (491, 13)\n",
      "cashflow: 0 rows dropped due to NaNs\n",
      "cashflow shape after cleaning: (491, 13)\n",
      "Shared (symbol, date) rows across all dfs: 491\n"
     ]
    }
   ],
   "source": [
    "aligned, common_pairs = clean_and_align({\n",
    "    \"income\": income_clean,\n",
    "    \"balance\": balance_clean,\n",
    "    \"cashflow\": cashflow_clean\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd99266-2982-49c8-85e5-4683cdd83aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['revenue_yoy', 'grossProfit_yoy', 'grossProfitRatio_yoy',\n",
      "       'costAndExpenses_yoy', 'ebitdaratio_yoy', 'operatingIncome_yoy',\n",
      "       'operatingIncomeRatio_yoy', 'incomeBeforeTax_yoy',\n",
      "       'incomeBeforeTaxRatio_yoy', 'netIncome_yoy', 'netIncomeRatio_yoy',\n",
      "       'eps_yoy', 'epsdiluted_yoy', 'weightedAverageShsOut_yoy',\n",
      "       'weightedAverageShsOutDil_yoy', 'symbol', 'date', 'symbol_date'],\n",
      "      dtype='object')\n",
      "Index(['cashAndCashEquivalents_yoy', 'cashAndShortTermInvestments_yoy',\n",
      "       'otherNonCurrentAssets_yoy', 'totalAssets_yoy', 'totalLiabilities_yoy',\n",
      "       'totalStockholdersEquity_yoy', 'totalEquity_yoy',\n",
      "       'totalLiabilitiesAndStockholdersEquity_yoy',\n",
      "       'totalLiabilitiesAndTotalEquity_yoy', 'netDebt_yoy', 'symbol', 'date',\n",
      "       'symbol_date'],\n",
      "      dtype='object')\n",
      "Index(['netIncome_yoy', 'changeInWorkingCapital_yoy',\n",
      "       'netCashProvidedByOperatingActivities_yoy',\n",
      "       'netCashUsedForInvestingActivites_yoy',\n",
      "       'netCashUsedProvidedByFinancingActivities_yoy', 'netChangeInCash_yoy',\n",
      "       'cashAtEndOfPeriod_yoy', 'cashAtBeginningOfPeriod_yoy',\n",
      "       'operatingCashFlow_yoy', 'freeCashFlow_yoy', 'symbol', 'date',\n",
      "       'symbol_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(income_clean.columns)\n",
    "print(balance_clean.columns)\n",
    "print(cashflow_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fed1b04-d0c6-4593-a018-e0f53440299b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INCOME FIRST 5 SYMBOLS:\n",
      "['AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL']\n",
      "\n",
      "INCOME LAST 5 SYMBOLS:\n",
      "['XYZ', 'YUM', 'ZBH', 'ZBRA', 'ZTS']\n",
      "\n",
      "BALANCE FIRST 5 SYMBOLS:\n",
      "['AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL']\n",
      "\n",
      "BALANCE LAST 5 SYMBOLS:\n",
      "['XYZ', 'YUM', 'ZBH', 'ZBRA', 'ZTS']\n",
      "\n",
      "CASHFLOW FIRST 5 SYMBOLS:\n",
      "['AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL']\n",
      "\n",
      "CASHFLOW LAST 5 SYMBOLS:\n",
      "['XYZ', 'YUM', 'ZBH', 'ZBRA', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "for name, df in {\"income\": income_clean, \"balance\": balance_clean, \"cashflow\": cashflow_clean}.items():\n",
    "    print(f\"\\n{name.upper()} FIRST 5 SYMBOLS:\")\n",
    "    print(df[\"symbol\"].head(5).to_list())\n",
    "    print(f\"\\n{name.upper()} LAST 5 SYMBOLS:\")\n",
    "    print(df[\"symbol\"].tail(5).to_list())\n",
    "    \n",
    "# just a check that the symbols are the same and aligned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd4fef13-9c56-4801-86b3-1d7904fc3e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_pca(df, selected_cols, n_components=5, scale=True):\n",
    "    \"\"\"\n",
    "    Run PCA on selected columns with optional scaling and visualize:\n",
    "      - Column variances\n",
    "      - Explained variance ratio of PCs\n",
    "    \"\"\"\n",
    "    sub_df = df[selected_cols].copy()\n",
    "    \n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(sub_df)\n",
    "        data_to_use = scaled\n",
    "        title_suffix = \" (post-standardization)\"\n",
    "    else:\n",
    "        data_to_use = sub_df.values\n",
    "        title_suffix = \" (raw)\"\n",
    "    \n",
    "    # Compute PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pcs = pca.fit_transform(data_to_use)\n",
    "    pcs_df = pd.DataFrame(pcs, index=sub_df.index, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "    \n",
    "    # Print some info\n",
    "    print(f\"PCA shape: {pcs_df.shape}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    \n",
    "    return pcs_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "512f12a1-643f-458b-ae19-f8fb82a8b909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shape: (491, 3)\n",
      "Explained variance ratio: [0.34710423 0.34377133 0.30912445]\n",
      "PCA shape: (491, 3)\n",
      "Explained variance ratio: [0.646486  0.3168122 0.0367018]\n",
      "PCA shape: (491, 3)\n",
      "Explained variance ratio: [6.80308141e-01 3.19691688e-01 1.71405147e-07]\n"
     ]
    }
   ],
   "source": [
    "income_cols = [\"revenue_yoy\",\"netIncome_yoy\",\"operatingIncomeRatio_yoy\"]\n",
    "balance_cols = [\"totalAssets_yoy\",\"totalLiabilities_yoy\",\"totalStockholdersEquity_yoy\"]\n",
    "cashflow_cols = [\"operatingCashFlow_yoy\",\"freeCashFlow_yoy\",\"netCashProvidedByOperatingActivities_yoy\"]\n",
    "\n",
    "income_pcs, income_pca_model = run_pca(aligned[\"income\"], income_cols, n_components=3)\n",
    "balance_pcs, balance_pca_model = run_pca(aligned[\"balance\"], balance_cols, n_components=3)\n",
    "cashflow_pcs, cashflow_pca_model = run_pca(aligned[\"cashflow\"], cashflow_cols, n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61229223-2e01-45a1-be31-ff084145b6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491, 4)\n",
      "(491, 4)\n",
      "(491, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_pcs[\"symbol\"] = aligned[\"income\"][\"symbol\"].values\n",
    "balance_pcs[\"symbol\"] = aligned[\"balance\"][\"symbol\"].values\n",
    "cashflow_pcs[\"symbol\"] = aligned[\"cashflow\"][\"symbol\"].values\n",
    "\n",
    "print(cashflow_pcs.shape)\n",
    "print(balance_pcs.shape)\n",
    "print(income_pcs.shape)\n",
    "\n",
    "cashflow_pcs.columns   \n",
    "pe_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d13adc9-7452-4516-93d4-c67b94e457e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged shape: (468, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>symbol</th>\n",
       "      <th>log_PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.236839</td>\n",
       "      <td>-0.057813</td>\n",
       "      <td>0.119444</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.645693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170229</td>\n",
       "      <td>-0.057766</td>\n",
       "      <td>0.036015</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>4.510585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196792</td>\n",
       "      <td>0.149132</td>\n",
       "      <td>-0.225770</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>3.375818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.058138</td>\n",
       "      <td>-0.071405</td>\n",
       "      <td>0.084858</td>\n",
       "      <td>ABT</td>\n",
       "      <td>2.858506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3 symbol    log_PE\n",
       "0 -0.236839 -0.057813  0.119444   AAPL  3.645693\n",
       "1 -0.170229 -0.057766  0.036015   ABBV  4.510585\n",
       "2  0.196792  0.149132 -0.225770   ABNB  3.375818\n",
       "3 -0.058138 -0.071405  0.084858    ABT  2.858506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pcs = pd.concat(\n",
    "    [income_pcs, balance_pcs, cashflow_pcs], axis=1\n",
    ")\n",
    "\n",
    "all_pcs = all_pcs.loc[:, ~all_pcs.columns.duplicated()]\n",
    "\n",
    "\n",
    "merged = pd.merge(all_pcs, pe_data[[\"symbol\", \"log_PE\"]], on=\"symbol\")\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "\n",
    "merged.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a5538ec-a122-47a6-854a-868ff37d0512",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variable      coef   std_err  R_squared  quartile\n",
      "0     const  2.512168  0.025053   0.026304         1\n",
      "1       PC1 -0.017309  0.016511   0.026304         1\n",
      "2       PC2 -0.013928  0.014614   0.026304         1\n",
      "3       PC3  0.022537  0.016594   0.026304         1\n",
      "4     const  3.042718  0.012145   0.010191         2\n",
      "5       PC1 -0.003696  0.041033   0.010191         2\n",
      "6       PC2 -0.127523  0.154594   0.010191         2\n",
      "7       PC3 -0.088242  0.098536   0.010191         2\n",
      "8     const  3.387777  0.012922   0.003285         3\n",
      "9       PC1  0.054271  0.093405   0.003285         3\n",
      "10      PC2  0.022564  0.099015   0.003285         3\n",
      "11      PC3  0.092381  0.170751   0.003285         3\n",
      "12    const  3.942280  0.092055   0.212034         4\n",
      "13      PC1 -2.504433  0.655548   0.212034         4\n",
      "14      PC2 -0.994669  1.376141   0.212034         4\n",
      "15      PC3 -3.989013  0.825462   0.212034         4\n"
     ]
    }
   ],
   "source": [
    "# Assume merged has all the features and log_PE\n",
    "X = merged.drop(columns=[\"symbol\", \"log_PE\"])\n",
    "y = merged[\"log_PE\"]\n",
    "\n",
    "# Add a constant for intercept\n",
    "X_const = sm.add_constant(X)\n",
    "\n",
    "# Create quartiles based on log_PE\n",
    "merged[\"PE_quartile\"] = pd.qcut(merged[\"log_PE\"], 4, labels=False)  # 0=lowest, 3=highest\n",
    "\n",
    "# Prepare a DataFrame to store results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Loop through quartiles\n",
    "for q in range(4):\n",
    "    mask = merged[\"PE_quartile\"] == q\n",
    "    X_q = X_const[mask]\n",
    "    y_q = y[mask]\n",
    "    \n",
    "    model_q = sm.OLS(y_q, X_q).fit()\n",
    "    \n",
    "    # Store coefficients and standard errors\n",
    "    coef_df = pd.DataFrame({\n",
    "        \"variable\": model_q.params.index,\n",
    "        \"coef\": model_q.params.values,\n",
    "        \"std_err\": model_q.bse.values,\n",
    "        \"R_squared\": model_q.rsquared,\n",
    "        \"quartile\": q+1  # human-friendly 1-4\n",
    "    })\n",
    "    \n",
    "    results_df = pd.concat([results_df, coef_df], ignore_index=True)\n",
    "\n",
    "# Show results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6841963a-74ea-4215-8852-bbd2b5cd669f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income 1, Balance 1, Cashflow 1, R²: 0.011\n",
      "  const: coef = 3.3008, t-stat = 92.753\n",
      "  income_PC1: coef = 0.0268, t-stat = 2.276\n",
      "  balance_PC1: coef = 0.0268, t-stat = 2.276\n",
      "  cashflow_PC1: coef = 0.0268, t-stat = 2.276\n",
      "Income 1, Balance 1, Cashflow 2, R²: 0.013\n",
      "  const: coef = 3.2998, t-stat = 92.708\n",
      "  income_PC1: coef = 0.0282, t-stat = 2.380\n",
      "  balance_PC1: coef = 0.0282, t-stat = 2.380\n",
      "  cashflow_PC1: coef = 0.0282, t-stat = 2.380\n",
      "  cashflow_PC2: coef = 0.0429, t-stat = 1.080\n",
      "Income 1, Balance 1, Cashflow 3, R²: 0.044\n",
      "  const: coef = 3.2993, t-stat = 94.068\n",
      "  income_PC1: coef = 0.0264, t-stat = 2.256\n",
      "  balance_PC1: coef = 0.0264, t-stat = 2.256\n",
      "  cashflow_PC1: coef = 0.0264, t-stat = 2.256\n",
      "  cashflow_PC2: coef = 0.0117, t-stat = 0.293\n",
      "  cashflow_PC3: coef = -0.1522, t-stat = -3.858\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['cashflow_symbol'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k_balance \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(balance_pcs_cols_prefixed)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k_cashflow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(cashflow_pcs_cols_prefixed)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     25\u001b[0m         \n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Subset first k PCs for each category\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         X_subset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[1;32m     28\u001b[0m             merged_prefixed[income_pcs_cols_prefixed[:k_income]],\n\u001b[1;32m     29\u001b[0m             merged_prefixed[balance_pcs_cols_prefixed[:k_balance]],\n\u001b[0;32m---> 30\u001b[0m             \u001b[43mmerged_prefixed\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcashflow_pcs_cols_prefixed\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mk_cashflow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m         ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m# Add intercept\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         X_subset \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_subset)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['cashflow_symbol'] not in index\""
     ]
    }
   ],
   "source": [
    "# --- Precompute numeric response ---\n",
    "y = merged[\"log_PE\"].astype(float)\n",
    "\n",
    "# --- Define PCA column groups with prefixes ---\n",
    "income_pcs_cols_prefixed = [f\"income_{c}\" for c in merged.columns if c in income_pcs.columns]\n",
    "balance_pcs_cols_prefixed = [f\"balance_{c}\" for c in merged.columns if c in balance_pcs.columns]\n",
    "cashflow_pcs_cols_prefixed = [f\"cashflow_{c}\" for c in merged.columns if c in cashflow_pcs.columns]\n",
    "\n",
    "# Add prefixed columns to merged temporarily\n",
    "merged_prefixed = pd.concat([\n",
    "    merged[[c for c in merged.columns if c in income_pcs.columns]].add_prefix(\"income_\"),\n",
    "    merged[[c for c in merged.columns if c in balance_pcs.columns]].add_prefix(\"balance_\"),\n",
    "    merged[[c for c in merged.columns if c in cashflow_pcs.columns]].add_prefix(\"cashflow_\")\n",
    "], axis=1)\n",
    "\n",
    "# Keep only numeric columns\n",
    "merged_prefixed = merged_prefixed.select_dtypes(include=[np.number])\n",
    "\n",
    "# --- Hyperparameter loop ---\n",
    "results = []\n",
    "\n",
    "for k_income in range(1, len(income_pcs_cols_prefixed)+1):\n",
    "    for k_balance in range(1, len(balance_pcs_cols_prefixed)+1):\n",
    "        for k_cashflow in range(1, len(cashflow_pcs_cols_prefixed)+1):\n",
    "            \n",
    "            # Subset first k PCs for each category\n",
    "            X_subset = pd.concat([\n",
    "                merged_prefixed[income_pcs_cols_prefixed[:k_income]],\n",
    "                merged_prefixed[balance_pcs_cols_prefixed[:k_balance]],\n",
    "                merged_prefixed[cashflow_pcs_cols_prefixed[:k_cashflow]]\n",
    "            ], axis=1)\n",
    "            \n",
    "            # Add intercept\n",
    "            X_subset = sm.add_constant(X_subset)\n",
    "\n",
    "            # Fit OLS\n",
    "            model = sm.OLS(y, X_subset).fit()\n",
    "\n",
    "            # Print R²\n",
    "            print(f\"Income {k_income}, Balance {k_balance}, Cashflow {k_cashflow}, R²: {model.rsquared:.3f}\")\n",
    "\n",
    "            # Print coefficients and t-stats\n",
    "            for var in model.params.index:\n",
    "                print(f\"  {var}: coef = {model.params[var]:.4f}, t-stat = {model.tvalues[var]:.3f}\")\n",
    "\n",
    "            # Store results\n",
    "            res = {\n",
    "                \"k_income\": k_income,\n",
    "                \"k_balance\": k_balance,\n",
    "                \"k_cashflow\": k_cashflow,\n",
    "                \"R_squared\": model.rsquared\n",
    "            }\n",
    "            for var in model.params.index:\n",
    "                res[f\"{var}_coef\"] = model.params[var]\n",
    "                res[f\"{var}_tstat\"] = model.tvalues[var]\n",
    "            results.append(res)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4b15a-dc38-4987-98af-029cf9d16292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
