{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9ed79e-112a-418f-b955-5c13dd46dd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a3d2046-ea29-42a8-94a4-d33602247506",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from JSON cache...\n",
      "         date symbol reportedCurrency         cik fillingDate  \\\n",
      "0  2024-09-28   AAPL              USD  0000320193  2024-11-01   \n",
      "1  2024-06-30   MSFT              USD  0000789019  2024-07-30   \n",
      "2  2024-12-31   AMZN              USD  0001018724  2025-02-07   \n",
      "3  2025-01-26   NVDA              USD  0001045810  2025-02-26   \n",
      "4  2024-12-31  GOOGL              USD  0001652044  2025-02-05   \n",
      "\n",
      "          acceptedDate calendarYear period       revenue  costOfRevenue  ...  \\\n",
      "0  2024-11-01 06:01:36         2024     FY  391035000000   210352000000  ...   \n",
      "1  2024-07-30 16:06:22         2024     FY  245122000000    74114000000  ...   \n",
      "2  2025-02-06 18:40:29         2024     FY  637959000000   326288000000  ...   \n",
      "3  2025-02-26 16:48:33         2025     FY  130497000000    32639000000  ...   \n",
      "4  2025-02-04 20:41:40         2024     FY  350018000000   146306000000  ...   \n",
      "\n",
      "   incomeBeforeTaxRatio  incomeTaxExpense     netIncome  netIncomeRatio  \\\n",
      "0              0.315790       29749000000   93736000000        0.239713   \n",
      "1              0.439728       19651000000   88136000000        0.359560   \n",
      "2              0.107394        9265000000   59248000000        0.092871   \n",
      "3              0.643892       11146000000   72880000000        0.558480   \n",
      "4              0.342311       19697000000  100118000000        0.286037   \n",
      "\n",
      "     eps  epsdiluted  weightedAverageShsOut  weightedAverageShsOutDil  \\\n",
      "0   6.11        6.08            15343783000               15408095000   \n",
      "1  11.86       11.80             7431000000                7469000000   \n",
      "2   5.66        5.53            10473000000               10721000000   \n",
      "3   2.97        2.94            24555000000               24804000000   \n",
      "4   8.04        8.04            12319000000               12447000000   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://www.sec.gov/Archives/edgar/data/320193...   \n",
      "1  https://www.sec.gov/Archives/edgar/data/789019...   \n",
      "2  https://www.sec.gov/Archives/edgar/data/101872...   \n",
      "3  https://www.sec.gov/Archives/edgar/data/104581...   \n",
      "4  https://www.sec.gov/Archives/edgar/data/165204...   \n",
      "\n",
      "                                           finalLink  \n",
      "0  https://www.sec.gov/Archives/edgar/data/320193...  \n",
      "1  https://www.sec.gov/Archives/edgar/data/789019...  \n",
      "2  https://www.sec.gov/Archives/edgar/data/101872...  \n",
      "3  https://www.sec.gov/Archives/edgar/data/104581...  \n",
      "4  https://www.sec.gov/Archives/edgar/data/165204...  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set up data folder and file paths\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "csv_file = os.path.join(data_folder, \"spy_tickers_sample.csv\")\n",
    "json_file = os.path.join(data_folder, \"income_statements.json\")\n",
    "\n",
    "# Try loading from cached JSON if it exists\n",
    "if os.path.exists(json_file):\n",
    "    print(\"Loading data from JSON cache...\")\n",
    "    with open(json_file, 'r') as f:\n",
    "        records = json.load(f)\n",
    "else:\n",
    "    # Load tickers\n",
    "    df = pd.read_csv(csv_file)\n",
    "    tickers = df['Ticker'].tolist()\n",
    "\n",
    "    API_KEY = 'YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6'\n",
    "    records = []\n",
    "\n",
    "    # Fetch most recent income statement per ticker\n",
    "    for ticker in tickers:\n",
    "        url = f'https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=1&apikey={API_KEY}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                row = data[0]\n",
    "                row['symbol'] = ticker\n",
    "                records.append(row)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(1)  # Rate limiting\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(\"Saved data to JSON cache.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "income_growth_df = pd.DataFrame(records)\n",
    "\n",
    "# Show sample\n",
    "print(income_growth_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526d7960-31a4-4faf-9fe0-eeeac6e157f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from JSON cache...\n",
      "  symbol        date fiscalYear period reportedCurrency  growthRevenue  \\\n",
      "0   AAPL  2024-09-28       2024     FY              USD       0.020220   \n",
      "1   MSFT  2024-06-30       2024     FY              USD       0.156700   \n",
      "2   AMZN  2024-12-31       2024     FY              USD       0.109909   \n",
      "3   NVDA  2025-01-26       2025     FY              USD       1.142034   \n",
      "4  GOOGL  2024-12-31       2024     FY              USD       0.138662   \n",
      "\n",
      "   growthCostOfRevenue  growthGrossProfit  growthGrossProfitRatio  \\\n",
      "0            -0.017676           0.068195                0.047024   \n",
      "1             0.125275           0.170871                0.012251   \n",
      "2             0.070713           0.154140                0.039851   \n",
      "3             0.963721           1.208934                0.031232   \n",
      "4             0.097306           0.170342                0.027821   \n",
      "\n",
      "   growthResearchAndDevelopmentExpenses  ...  growthEPSDiluted  \\\n",
      "0                              0.048638  ...         -0.008157   \n",
      "1                              0.085126  ...          0.219008   \n",
      "2                              0.034127  ...          0.906897   \n",
      "3                              0.488646  ...          1.470588   \n",
      "4                              0.085830  ...          0.386207   \n",
      "\n",
      "   growthWeightedAverageShsOut  growthWeightedAverageShsOutDil  growthEBIT  \\\n",
      "0                    -0.025435                       -0.025578    0.077996   \n",
      "1                    -0.002015                       -0.000401    0.213006   \n",
      "2                     0.016401                        0.021826    0.743293   \n",
      "3                    -0.005468                       -0.005453    1.473162   \n",
      "4                    -0.024624                       -0.021616    0.395908   \n",
      "\n",
      "   growthNonOperatingIncomeExcludingInterest  growthNetInterestIncome  \\\n",
      "0                                   0.000000                 1.000000   \n",
      "1                                   0.532293                -0.783626   \n",
      "2                                   0.375611                10.746781   \n",
      "3                                  -1.556664                 1.527094   \n",
      "4                                  -3.441686                 0.184706   \n",
      "\n",
      "   growthTotalOtherIncomeExpensesNet  growthNetIncomeFromContinuingOperations  \\\n",
      "0                           1.476106                                -0.033600   \n",
      "1                          -3.088832                                 0.218004   \n",
      "2                          -0.970213                                 0.947346   \n",
      "3                           2.041371                                 1.448925   \n",
      "4                           4.214185                                 0.356704   \n",
      "\n",
      "   growthOtherAdjustmentsToNetIncome  growthNetIncomeDeductions  \n",
      "0                                0.0                        0.0  \n",
      "1                                0.0                        0.0  \n",
      "2                                0.0                        0.0  \n",
      "3                                0.0                        0.0  \n",
      "4                                0.0                        0.0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set up data folder and file paths\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "csv_file = os.path.join(data_folder, \"spy_tickers_sample.csv\")\n",
    "json_file = os.path.join(data_folder, \"income_growth.json\")\n",
    "\n",
    "# Try loading from cached JSON if it exists\n",
    "if os.path.exists(json_file):\n",
    "    print(\"Loading data from JSON cache...\")\n",
    "    with open(json_file, 'r') as f:\n",
    "        records = json.load(f)\n",
    "else:\n",
    "    # Load tickers\n",
    "    df = pd.read_csv(csv_file)\n",
    "    tickers = df['Ticker'].tolist()\n",
    "\n",
    "    API_KEY = 'YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6'\n",
    "    records = []\n",
    "\n",
    "    # Fetch most recent income statement per ticker\n",
    "    for ticker in tickers:\n",
    "        url = f'https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=1&apikey={API_KEY}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                row = data[0]\n",
    "                row['symbol'] = ticker\n",
    "                records.append(row)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(1)  # Rate limiting\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(\"Saved data to JSON cache.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "income_growth_df = pd.DataFrame(records)\n",
    "\n",
    "# Show sample\n",
    "print(income_growth_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc5f342-6179-42f1-9306-36d6c6a41ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading growth data from JSON cache...\n",
      "Columns in growth DataFrame: ['symbol', 'date', 'fiscalYear', 'period', 'reportedCurrency', 'growthRevenue', 'growthCostOfRevenue', 'growthGrossProfit', 'growthGrossProfitRatio', 'growthResearchAndDevelopmentExpenses', 'growthGeneralAndAdministrativeExpenses', 'growthSellingAndMarketingExpenses', 'growthOtherExpenses', 'growthOperatingExpenses', 'growthCostAndExpenses', 'growthInterestIncome', 'growthInterestExpense', 'growthDepreciationAndAmortization', 'growthEBITDA', 'growthOperatingIncome', 'growthIncomeBeforeTax', 'growthIncomeTaxExpense', 'growthNetIncome', 'growthEPS', 'growthEPSDiluted', 'growthWeightedAverageShsOut', 'growthWeightedAverageShsOutDil', 'growthEBIT', 'growthNonOperatingIncomeExcludingInterest', 'growthNetInterestIncome', 'growthTotalOtherIncomeExpensesNet', 'growthNetIncomeFromContinuingOperations', 'growthOtherAdjustmentsToNetIncome', 'growthNetIncomeDeductions']\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "data_folder  = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "csv_file     = os.path.join(data_folder, \"spy_tickers_sample.csv\")\n",
    "output_file  = os.path.join(data_folder, \"income_growth.json\")\n",
    "\n",
    "# API setup\n",
    "API_KEY  = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "BASE_URL = \"https://financialmodelingprep.com/stable/income-statement-growth\"\n",
    "\n",
    "# Try loading from cache\n",
    "if os.path.exists(output_file):\n",
    "    print(\"Loading growth data from JSON cache...\")\n",
    "    with open(output_file, \"r\") as f:\n",
    "        growth_records = json.load(f)\n",
    "\n",
    "else:\n",
    "    print(\"No cache found — fetching growth data from API...\")\n",
    "    # Load tickers\n",
    "    df       = pd.read_csv(csv_file)\n",
    "    tickers  = df['Ticker'].tolist()\n",
    "    growth_records = []\n",
    "\n",
    "    # Fetch and flatten all periods (Solution B)\n",
    "    for ticker in tickers:\n",
    "        url = f\"{BASE_URL}?symbol={ticker}&apikey={API_KEY}\"\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "\n",
    "            if isinstance(data, list) and data:\n",
    "                for period in data:\n",
    "                    period['symbol'] = ticker\n",
    "                    growth_records.append(period)\n",
    "            else:\n",
    "                print(f\"  • no growth data for {ticker}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "\n",
    "        time.sleep(1)  # respect rate limits\n",
    "\n",
    "    # Save to JSON cache\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(growth_records, f, indent=2)\n",
    "    print(f\"Saved {len(growth_records)} records to JSON cache.\")\n",
    "\n",
    "# Convert to DataFrame and inspect\n",
    "df_growth = pd.DataFrame(growth_records)\n",
    "print(\"Columns in growth DataFrame:\", df_growth.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fffff96-d96e-45dc-a7d7-47616b48c94b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ratios from JSON cache...\n",
      "  symbol        date calendarYear period  currentRatio  quickRatio  cashRatio  \\\n",
      "0   AAPL  2024-09-28         2024     FY      0.867313    0.826007   0.169753   \n",
      "1   MSFT  2025-06-30         2025     FY      1.353446    1.346804   0.214151   \n",
      "2   AMZN  2024-12-31         2024     FY      1.063735    0.873054   0.439049   \n",
      "3   NVDA  2025-01-26         2025     FY      4.439851    3.881310   0.475924   \n",
      "4  GOOGL  2024-12-31         2024     FY      1.836931    1.836931   0.263302   \n",
      "\n",
      "   daysOfSalesOutstanding  daysOfInventoryOutstanding  operatingCycle  ...  \\\n",
      "0               61.832560                   12.642571       74.475130  ...   \n",
      "1               90.568517                    3.898054       94.466572  ...   \n",
      "2               31.725573                   38.273274       69.998847  ...   \n",
      "3               64.512786                  112.724042      177.236828  ...   \n",
      "4               54.580336                    0.000000       54.580336  ...   \n",
      "\n",
      "   priceToSalesRatio  priceEarningsRatio  priceToFreeCashFlowsRatio  \\\n",
      "0           8.938229           37.287278                  32.122569   \n",
      "1          13.123655           36.307335                  51.629617   \n",
      "2           3.601597           38.780574                  69.884770   \n",
      "3          22.282528           39.898506                  47.784055   \n",
      "4           6.662477           23.292382                  32.048633   \n",
      "\n",
      "   priceToOperatingCashFlowsRatio  priceCashFlowRatio  \\\n",
      "0                       29.556381           29.556381   \n",
      "1                       27.153307           27.153307   \n",
      "2                       19.828538           19.828538   \n",
      "3                       45.371329           45.371329   \n",
      "4                       18.611375           18.611375   \n",
      "\n",
      "   priceEarningsToGrowthRatio  priceSalesRatio  dividendYield  \\\n",
      "0                  -45.937927         8.938229       0.004359   \n",
      "1                    2.340245        13.123655       0.006513   \n",
      "2                    0.422150         3.601597       0.000000   \n",
      "3                    0.274302        22.282528       0.000287   \n",
      "4                    0.618307         6.662477       0.003157   \n",
      "\n",
      "   enterpriseValueMultiple  priceFairValue  \n",
      "0                26.617033       61.372438  \n",
      "1                23.273465       10.764118  \n",
      "2                18.978254        8.034659  \n",
      "3                33.777402       36.655907  \n",
      "4                17.238443        7.173490  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "tickers_csv_path = os.path.join(data_folder, \"spy_tickers_sample.csv\")\n",
    "output_json_path = os.path.join(data_folder, \"ratios.json\")\n",
    "\n",
    "# Try loading from cache\n",
    "if os.path.exists(output_json_path):\n",
    "    print(\"Loading ratios from JSON cache...\")\n",
    "    with open(output_json_path, \"r\") as f:\n",
    "        all_ratios = json.load(f)\n",
    "else:\n",
    "    print(\"No cache found — fetching ratios from API...\")\n",
    "    tickers_df = pd.read_csv(tickers_csv_path)\n",
    "    tickers = tickers_df['Ticker'].dropna().unique().tolist()\n",
    "\n",
    "    api_key = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "    base_url = \"https://financialmodelingprep.com/api/v3/ratios/{}?limit=1&apikey={}\"\n",
    "\n",
    "    all_ratios = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            url = base_url.format(ticker, api_key)\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                all_ratios.append(data[0])\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "\n",
    "    # Save to cache\n",
    "    with open(output_json_path, \"w\") as f:\n",
    "        json.dump(all_ratios, f, indent=2)\n",
    "    print(f\"Saved {len(all_ratios)} records to JSON cache.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_ratios = pd.DataFrame(all_ratios)\n",
    "print(df_ratios.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b14bd7-484b-4c26-8c10-5477475b67a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'P_E'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'P_E'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert columns to numeric, coercing errors to NaN\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_growth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_E\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdf_growth\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mP_E\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_growth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrowthEPSDiluted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_growth[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrowthEPSDiluted\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Drop rows with missing values in P_E or growthEPSDiluted\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'P_E'"
     ]
    }
   ],
   "source": [
    "# Convert columns to numeric, coercing errors to NaN\n",
    "df_growth['P_E'] = pd.to_numeric(df_growth['P_E'], errors='coerce')\n",
    "df_growth['growthEPSDiluted'] = pd.to_numeric(df_growth['growthEPSDiluted'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values in P_E or growthEPSDiluted\n",
    "reg_df = df_growth.dropna(subset=['P_E', 'growthEPSDiluted']).copy()\n",
    "\n",
    "# Log-transform the P/E ratio\n",
    "reg_df['ln_PE'] = np.log(reg_df['P_E'])\n",
    "\n",
    "# Setup regression\n",
    "X = sm.add_constant(reg_df['growthEPSDiluted'])\n",
    "y = reg_df['ln_PE']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "print(''' the coefficient is the expected p/e when the growth is 0. the coefficient beta is the expected percentage increase in the p/e per unit increase in the independent var, aka the growth  ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
