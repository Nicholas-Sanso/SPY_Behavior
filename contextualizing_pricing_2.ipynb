{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9ed79e-112a-418f-b955-5c13dd46dd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from pygam import LinearGAM, s\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2982057a-32e3-43e6-b761-6240815efa25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from CSV cache...\n",
      "(503, 8)\n",
      "Index(['symbol', 'name', 'sector', 'subSector', 'headQuarter',\n",
      "       'dateFirstAdded', 'cik', 'founded'],\n",
      "      dtype='object')\n",
      "  symbol                  name                  sector  \\\n",
      "0    XYZ           Block, Inc.              Technology   \n",
      "1    TTD  The Trade Desk, Inc.              Technology   \n",
      "2   DDOG               Datadog              Technology   \n",
      "3   COIN       Coinbase Global      Financial Services   \n",
      "4   DASH              DoorDash  Communication Services   \n",
      "\n",
      "                            subSector              headQuarter dateFirstAdded  \\\n",
      "0           Software - Infrastructure      Oakland, California     2025-07-23   \n",
      "1              Software - Application      Ventura, California     2025-07-18   \n",
      "2              Software - Application  New York City, New York     2025-07-09   \n",
      "3  Financial - Data & Stock Exchanges     Wilmington, Delaware     2025-05-19   \n",
      "4      Internet Content & Information        San Francisco, CA     2025-03-24   \n",
      "\n",
      "       cik founded  \n",
      "0  1512673    2009  \n",
      "1  1671933    2009  \n",
      "2  1561550    2010  \n",
      "3  1679788    2012  \n",
      "4  1792789    2013  \n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# --- LOAD FROM CACHE OR FETCH ---\n",
    "if os.path.exists(tickers_csv_file):\n",
    "    print(\"Loading tickers from CSV cache...\")\n",
    "    df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "else:\n",
    "    print(\"Fetching tickers from API...\")\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}\"\n",
    "    df_sp500 = pd.DataFrame(requests.get(url).json())\n",
    "\n",
    "    # Save to CSV\n",
    "    df_sp500.to_csv(tickers_csv_file, index=False)\n",
    "    print(f\"Saved {len(df_sp500)} tickers to CSV cache.\")\n",
    "\n",
    "    \n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()\n",
    "# --- PREVIEW ---\n",
    "print(df_sp500.shape)\n",
    "print(df_sp500.columns)\n",
    "print(df_sp500.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7840d0-3280-4f6b-8164-3d1996487ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/price_and_earnings.json\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# Load tickers\n",
    "df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()\n",
    "\n",
    "# Output file\n",
    "output_file = os.path.join(data_folder, \"price_and_earnings.json\")\n",
    "\n",
    "def fetch_price_and_earnings(tickers, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        return pd.DataFrame(json.load(open(output_file)))\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Get current price\n",
    "            quote_url = f\"https://financialmodelingprep.com/api/v3/quote/{ticker}?apikey={API_KEY}\"\n",
    "            price_data = requests.get(quote_url).json()\n",
    "            if not price_data:\n",
    "                continue\n",
    "            price = price_data[0][\"price\"]\n",
    "\n",
    "            # Get latest annual income statement (EPS or netIncome)\n",
    "            income_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=1&apikey={API_KEY}\"\n",
    "            income_data = requests.get(income_url).json()\n",
    "            if not income_data:\n",
    "                continue\n",
    "            eps = income_data[0].get(\"eps\")\n",
    "            net_income = income_data[0].get(\"netIncome\")\n",
    "\n",
    "            records.append({\n",
    "                \"symbol\": ticker,\n",
    "                \"price\": price,\n",
    "                \"eps\": eps,\n",
    "                \"netIncome\": net_income\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(0.2)  # polite rate limit\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "price_earnings_df = fetch_price_and_earnings(tickers, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb737c07-dc25-4514-858c-f5178907b5be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows used: 480\n",
      "0    2.741115\n",
      "1    4.033134\n",
      "2    5.514162\n",
      "3    3.434049\n",
      "4    6.756855\n",
      "Name: log_PE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Only keep rows with positive EPS\n",
    "pe_data = price_earnings_df[price_earnings_df[\"eps\"] > 0].copy()\n",
    "\n",
    "# Compute log(PE)\n",
    "pe_data[\"log_PE\"] = np.log(pe_data[\"price\"] / pe_data[\"eps\"])\n",
    "\n",
    "# Optional: store just the series if you want\n",
    "pe_series = pe_data[\"log_PE\"]\n",
    "\n",
    "# Print row count for reference\n",
    "print(f\"Rows used: {len(pe_series)}\")\n",
    "print(pe_series.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1844560d-77dc-4f2a-8993-96bb263662be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/income-statement_annual_limit2.json\n",
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/balance-sheet-statement_annual_limit2.json\n",
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/cash-flow-statement_annual_limit2.json\n",
      "Income shape: (1006, 38)\n",
      "Balance shape: (1006, 54)\n",
      "Cash flow shape: (1006, 40)\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'revenue', 'costOfRevenue',\n",
      "       'grossProfit', 'grossProfitRatio', 'researchAndDevelopmentExpenses',\n",
      "       'generalAndAdministrativeExpenses', 'sellingAndMarketingExpenses',\n",
      "       'sellingGeneralAndAdministrativeExpenses', 'otherExpenses',\n",
      "       'operatingExpenses', 'costAndExpenses', 'interestIncome',\n",
      "       'interestExpense', 'depreciationAndAmortization', 'ebitda',\n",
      "       'ebitdaratio', 'operatingIncome', 'operatingIncomeRatio',\n",
      "       'totalOtherIncomeExpensesNet', 'incomeBeforeTax',\n",
      "       'incomeBeforeTaxRatio', 'incomeTaxExpense', 'netIncome',\n",
      "       'netIncomeRatio', 'eps', 'epsdiluted', 'weightedAverageShsOut',\n",
      "       'weightedAverageShsOutDil', 'link', 'finalLink'],\n",
      "      dtype='object')\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'cashAndCashEquivalents',\n",
      "       'shortTermInvestments', 'cashAndShortTermInvestments', 'netReceivables',\n",
      "       'inventory', 'otherCurrentAssets', 'totalCurrentAssets',\n",
      "       'propertyPlantEquipmentNet', 'goodwill', 'intangibleAssets',\n",
      "       'goodwillAndIntangibleAssets', 'longTermInvestments', 'taxAssets',\n",
      "       'otherNonCurrentAssets', 'totalNonCurrentAssets', 'otherAssets',\n",
      "       'totalAssets', 'accountPayables', 'shortTermDebt', 'taxPayables',\n",
      "       'deferredRevenue', 'otherCurrentLiabilities', 'totalCurrentLiabilities',\n",
      "       'longTermDebt', 'deferredRevenueNonCurrent',\n",
      "       'deferredTaxLiabilitiesNonCurrent', 'otherNonCurrentLiabilities',\n",
      "       'totalNonCurrentLiabilities', 'otherLiabilities',\n",
      "       'capitalLeaseObligations', 'totalLiabilities', 'preferredStock',\n",
      "       'commonStock', 'retainedEarnings',\n",
      "       'accumulatedOtherComprehensiveIncomeLoss',\n",
      "       'othertotalStockholdersEquity', 'totalStockholdersEquity',\n",
      "       'totalEquity', 'totalLiabilitiesAndStockholdersEquity',\n",
      "       'minorityInterest', 'totalLiabilitiesAndTotalEquity',\n",
      "       'totalInvestments', 'totalDebt', 'netDebt', 'link', 'finalLink'],\n",
      "      dtype='object')\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'netIncome',\n",
      "       'depreciationAndAmortization', 'deferredIncomeTax',\n",
      "       'stockBasedCompensation', 'changeInWorkingCapital',\n",
      "       'accountsReceivables', 'inventory', 'accountsPayables',\n",
      "       'otherWorkingCapital', 'otherNonCashItems',\n",
      "       'netCashProvidedByOperatingActivities',\n",
      "       'investmentsInPropertyPlantAndEquipment', 'acquisitionsNet',\n",
      "       'purchasesOfInvestments', 'salesMaturitiesOfInvestments',\n",
      "       'otherInvestingActivites', 'netCashUsedForInvestingActivites',\n",
      "       'debtRepayment', 'commonStockIssued', 'commonStockRepurchased',\n",
      "       'dividendsPaid', 'otherFinancingActivites',\n",
      "       'netCashUsedProvidedByFinancingActivities',\n",
      "       'effectOfForexChangesOnCash', 'netChangeInCash', 'cashAtEndOfPeriod',\n",
      "       'cashAtBeginningOfPeriod', 'operatingCashFlow', 'capitalExpenditure',\n",
      "       'freeCashFlow', 'link', 'finalLink'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def fetch_statement(endpoint, tickers, period, limit, data_folder):\n",
    "    \"\"\"Fetch statements with unique JSON filename based on endpoint, period, limit.\"\"\"\n",
    "    output_file = os.path.join(\n",
    "        data_folder,\n",
    "        f\"{endpoint}_{period}_limit{limit}.json\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        with open(output_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/{endpoint}/{ticker}?period={period}&limit={limit}&apikey={API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                for row in data:\n",
    "                    row[\"symbol\"] = ticker\n",
    "                records.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker} ({endpoint}): {e}\")\n",
    "        time.sleep(.2)  # API polite rate limit\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "income_data_2_years   = fetch_statement(\"income-statement\", tickers, \"annual\", 2, data_folder)\n",
    "balance_data_2_years  = fetch_statement(\"balance-sheet-statement\", tickers, \"annual\", 2, data_folder)\n",
    "cashflow_data_2_years = fetch_statement(\"cash-flow-statement\", tickers, \"annual\", 2, data_folder)\n",
    "\n",
    "# Convert to DataFrames\n",
    "income_data_2_years   = pd.DataFrame(income_data_2_years)\n",
    "balance_data_2_years  = pd.DataFrame(balance_data_2_years)\n",
    "cashflow_data_2_years = pd.DataFrame(cashflow_data_2_years)\n",
    "\n",
    "print(\"Income shape:\", income_data_2_years.shape)\n",
    "print(\"Balance shape:\", balance_data_2_years.shape)\n",
    "print(\"Cash flow shape:\", cashflow_data_2_years.shape)\n",
    "\n",
    "print(income_data_2_years.columns)\n",
    "print(balance_data_2_years.columns)\n",
    "print(cashflow_data_2_years.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6e9e1d-7967-4d9d-bedd-c234025a3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_symbol_date(df):\n",
    "    return df.sort_values([\"symbol\", \"date\"])\n",
    "\n",
    "\n",
    "def compute_yoy_growth(df, exclude_cols=[\"symbol\", \"date\",\"link\",\"finalLink\"]):\n",
    "    numeric_cols = df.select_dtypes(include=[float, int]).columns\n",
    "    numeric_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "    \n",
    "    df_growth = df.copy()\n",
    "    for col in numeric_cols:\n",
    "        df_growth[col + \"_yoy\"] = df.groupby(\"symbol\")[col].pct_change()\n",
    "    \n",
    "    return df_growth\n",
    "\n",
    "\n",
    "income_sorted = sort_by_symbol_date(income_data_2_years)\n",
    "balance_sorted = sort_by_symbol_date(balance_data_2_years)\n",
    "cashflow_sorted = sort_by_symbol_date(cashflow_data_2_years)\n",
    "\n",
    "income_growth = compute_yoy_growth(income_sorted)\n",
    "balance_growth = compute_yoy_growth(balance_sorted)\n",
    "cashflow_growth = compute_yoy_growth(cashflow_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130f17b0-b137-4386-b95c-58b08ed4a839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income 0/NaN counts per YoY column:\n",
      "                                             zeros  nans\n",
      "revenue_yoy                                      0   503\n",
      "grossProfit_yoy                                  0   503\n",
      "costAndExpenses_yoy                              0   503\n",
      "ebitdaratio_yoy                                  0   503\n",
      "operatingIncome_yoy                              0   503\n",
      "operatingIncomeRatio_yoy                         0   503\n",
      "incomeBeforeTax_yoy                              0   503\n",
      "incomeBeforeTaxRatio_yoy                         0   503\n",
      "netIncomeRatio_yoy                               0   503\n",
      "ebitda_yoy                                       0   504\n",
      "operatingExpenses_yoy                            0   507\n",
      "costOfRevenue_yoy                                0   510\n",
      "totalOtherIncomeExpensesNet_yoy                  0   535\n",
      "generalAndAdministrativeExpenses_yoy             0   756\n",
      "netIncome_yoy                                    1   503\n",
      "eps_yoy                                          1   503\n",
      "epsdiluted_yoy                                   1   503\n",
      "depreciationAndAmortization_yoy                  1   508\n",
      "incomeTaxExpense_yoy                             1   508\n",
      "sellingGeneralAndAdministrativeExpenses_yoy      1   530\n",
      "otherExpenses_yoy                                1   642\n",
      "researchAndDevelopmentExpenses_yoy               1   792\n",
      "sellingAndMarketingExpenses_yoy                  3   841\n",
      "interestIncome_yoy                               4   667\n",
      "weightedAverageShsOut_yoy                        7   503\n",
      "grossProfitRatio_yoy                             9   503\n",
      "weightedAverageShsOutDil_yoy                     9   503\n",
      "interestExpense_yoy                              9   530\n",
      "\n",
      "Balance 0/NaN counts per YoY column:\n",
      "                                             zeros  nans\n",
      "otherNonCurrentAssets_yoy                        0   503\n",
      "totalAssets_yoy                                  0   503\n",
      "totalLiabilities_yoy                             0   503\n",
      "totalStockholdersEquity_yoy                      0   503\n",
      "totalEquity_yoy                                  0   503\n",
      "totalLiabilitiesAndStockholdersEquity_yoy        0   503\n",
      "totalLiabilitiesAndTotalEquity_yoy               0   503\n",
      "totalNonCurrentAssets_yoy                        0   504\n",
      "totalCurrentAssets_yoy                           0   505\n",
      "longTermDebt_yoy                                 0   505\n",
      "totalNonCurrentLiabilities_yoy                   0   505\n",
      "retainedEarnings_yoy                             0   505\n",
      "otherNonCurrentLiabilities_yoy                   0   508\n",
      "netReceivables_yoy                               0   513\n",
      "accountPayables_yoy                              0   530\n",
      "shortTermInvestments_yoy                         0   780\n",
      "otherAssets_yoy                                  0   971\n",
      "otherLiabilities_yoy                             0   985\n",
      "cashAndCashEquivalents_yoy                       1   503\n",
      "cashAndShortTermInvestments_yoy                  1   503\n",
      "totalDebt_yoy                                    1   504\n",
      "totalCurrentLiabilities_yoy                      1   508\n",
      "otherCurrentLiabilities_yoy                      1   510\n",
      "propertyPlantEquipmentNet_yoy                    1   511\n",
      "otherCurrentAssets_yoy                           1   536\n",
      "othertotalStockholdersEquity_yoy                 1   547\n",
      "totalInvestments_yoy                             1   602\n",
      "longTermInvestments_yoy                          1   658\n",
      "deferredTaxLiabilitiesNonCurrent_yoy             1   665\n",
      "taxPayables_yoy                                  1   674\n",
      "deferredRevenue_yoy                              1   731\n",
      "netDebt_yoy                                      2   503\n",
      "capitalLeaseObligations_yoy                      2   605\n",
      "taxAssets_yoy                                    2   752\n",
      "inventory_yoy                                    3   666\n",
      "deferredRevenueNonCurrent_yoy                    3   869\n",
      "accumulatedOtherComprehensiveIncomeLoss_yoy      5   515\n",
      "intangibleAssets_yoy                             5   586\n",
      "shortTermDebt_yoy                                6   539\n",
      "minorityInterest_yoy                            13   719\n",
      "goodwillAndIntangibleAssets_yoy                 24   539\n",
      "preferredStock_yoy                              27   949\n",
      "goodwill_yoy                                    73   553\n",
      "commonStock_yoy                                244   534\n",
      "\n",
      "Cashflow 0/NaN counts per YoY column:\n",
      "                                              zeros  nans\n",
      "netCashProvidedByOperatingActivities_yoy          0   503\n",
      "netCashUsedForInvestingActivites_yoy              0   503\n",
      "netCashUsedProvidedByFinancingActivities_yoy      0   503\n",
      "cashAtBeginningOfPeriod_yoy                       0   503\n",
      "operatingCashFlow_yoy                             0   503\n",
      "freeCashFlow_yoy                                  0   503\n",
      "otherWorkingCapital_yoy                           0   506\n",
      "investmentsInPropertyPlantAndEquipment_yoy        0   529\n",
      "deferredIncomeTax_yoy                             0   567\n",
      "effectOfForexChangesOnCash_yoy                    0   636\n",
      "inventory_yoy                                     0   660\n",
      "purchasesOfInvestments_yoy                        0   672\n",
      "commonStockIssued_yoy                             0   791\n",
      "netIncome_yoy                                     1   503\n",
      "netChangeInCash_yoy                               1   503\n",
      "cashAtEndOfPeriod_yoy                             1   503\n",
      "depreciationAndAmortization_yoy                   1   507\n",
      "capitalExpenditure_yoy                            1   527\n",
      "accountsReceivables_yoy                           1   561\n",
      "accountsPayables_yoy                              1   574\n",
      "acquisitionsNet_yoy                               1   618\n",
      "salesMaturitiesOfInvestments_yoy                  1   665\n",
      "changeInWorkingCapital_yoy                        2   503\n",
      "otherNonCashItems_yoy                             2   504\n",
      "debtRepayment_yoy                                 2   536\n",
      "dividendsPaid_yoy                                 2   597\n",
      "otherFinancingActivites_yoy                       3   511\n",
      "otherInvestingActivites_yoy                       5   532\n",
      "stockBasedCompensation_yoy                        5   580\n",
      "commonStockRepurchased_yoy                        8   568\n"
     ]
    }
   ],
   "source": [
    "def count_zeros_nans_yoy(df):\n",
    "    # Keep only numeric columns that end with \"_yoy\"\n",
    "    numeric_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c.endswith(\"_yoy\")]\n",
    "    \n",
    "    # Count zeros and NaNs\n",
    "    zero_counts = (df[numeric_cols] == 0).sum()\n",
    "    nan_counts = df[numeric_cols].isna().sum()\n",
    "    \n",
    "    # Combine into a single DataFrame\n",
    "    summary = pd.DataFrame({\n",
    "        \"zeros\": zero_counts,\n",
    "        \"nans\": nan_counts\n",
    "    }).sort_values(by=[\"zeros\", \"nans\"], ascending=True)\n",
    "    \n",
    "    # Force full display\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "        print(summary)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "print(\"Income 0/NaN counts per YoY column:\")\n",
    "income_summary = count_zeros_nans_yoy(income_growth)\n",
    "\n",
    "print(\"\\nBalance 0/NaN counts per YoY column:\")\n",
    "balance_summary = count_zeros_nans_yoy(balance_growth)\n",
    "\n",
    "print(\"\\nCashflow 0/NaN counts per YoY column:\")\n",
    "cashflow_summary = count_zeros_nans_yoy(cashflow_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676f2825-768b-4ae3-bb05-0fba40fcac2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_yoy_columns(df, nan_threshold=503, keep_cols=[\"symbol\",\"date\"]):\n",
    "    \"\"\"Select _yoy numeric columns, replace inf, drop rows/columns with too many NaNs.\"\"\"\n",
    "    yoy_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c.endswith(\"_yoy\")]\n",
    "    sub_df = df[yoy_cols + keep_cols].copy()  # Keep symbol/date columns\n",
    "    \n",
    "    # Drop columns with too many NaNs (only apply to yoy columns)\n",
    "    valid_yoy_cols = [c for c in yoy_cols if sub_df[c].isna().sum() <= nan_threshold]\n",
    "    sub_df = sub_df[valid_yoy_cols + keep_cols]\n",
    "    \n",
    "    # Replace infinities with NaN and drop rows with any remaining NaNs (only apply to yoy columns)\n",
    "    sub_df[valid_yoy_cols] = sub_df[valid_yoy_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    sub_df.dropna(subset=valid_yoy_cols, inplace=True)\n",
    "    \n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477b34ec-53ea-4a6b-9ddb-490c54be9261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 0: Clean _yoy columns\n",
    "income_clean = clean_yoy_columns(income_growth)\n",
    "balance_clean = clean_yoy_columns(balance_growth)\n",
    "cashflow_clean = clean_yoy_columns(cashflow_growth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f7de5d-cb6c-4ffb-90d8-21e3ee14d871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Keep only common (symbol, date) pairs\n",
    "for df in [income_clean, balance_clean, cashflow_clean]:\n",
    "    df[\"symbol_date\"] = list(zip(df[\"symbol\"], df[\"date\"]))\n",
    "\n",
    "common_pairs = (\n",
    "    set(income_clean[\"symbol_date\"])\n",
    "    & set(balance_clean[\"symbol_date\"])\n",
    "    & set(cashflow_clean[\"symbol_date\"])\n",
    ")\n",
    "\n",
    "income_clean = income_clean[income_clean[\"symbol_date\"].isin(common_pairs)].copy()\n",
    "balance_clean = balance_clean[balance_clean[\"symbol_date\"].isin(common_pairs)].copy()\n",
    "cashflow_clean = cashflow_clean[cashflow_clean[\"symbol_date\"].isin(common_pairs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45ff5cc-0343-463b-a89d-32c3f8b744a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and aligned shapes: (491, 18) (491, 13) (491, 13)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Sort consistently\n",
    "income_clean = income_clean.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "balance_clean = balance_clean.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "cashflow_clean = cashflow_clean.sort_values([\"symbol\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Cleaned and aligned shapes:\", income_clean.shape, balance_clean.shape, cashflow_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e8cc83-3623-40e7-bc09-5c41e4e8f305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue_yoy</th>\n",
       "      <th>grossProfit_yoy</th>\n",
       "      <th>grossProfitRatio_yoy</th>\n",
       "      <th>costAndExpenses_yoy</th>\n",
       "      <th>ebitdaratio_yoy</th>\n",
       "      <th>operatingIncome_yoy</th>\n",
       "      <th>operatingIncomeRatio_yoy</th>\n",
       "      <th>incomeBeforeTax_yoy</th>\n",
       "      <th>incomeBeforeTaxRatio_yoy</th>\n",
       "      <th>netIncome_yoy</th>\n",
       "      <th>netIncomeRatio_yoy</th>\n",
       "      <th>eps_yoy</th>\n",
       "      <th>epsdiluted_yoy</th>\n",
       "      <th>weightedAverageShsOut_yoy</th>\n",
       "      <th>weightedAverageShsOutDil_yoy</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02022</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.047024</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.049055</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.056631</td>\n",
       "      <td>0.085716</td>\n",
       "      <td>0.064198</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>-0.052753</td>\n",
       "      <td>-0.008117</td>\n",
       "      <td>-0.008157</td>\n",
       "      <td>-0.025435</td>\n",
       "      <td>-0.025578</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>(AAPL, 2024-09-28)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   revenue_yoy  grossProfit_yoy  grossProfitRatio_yoy  costAndExpenses_yoy  \\\n",
       "0      0.02022         0.068195              0.047024            -0.004331   \n",
       "\n",
       "   ebitdaratio_yoy  operatingIncome_yoy  operatingIncomeRatio_yoy  \\\n",
       "0         0.049055             0.077996                  0.056631   \n",
       "\n",
       "   incomeBeforeTax_yoy  incomeBeforeTaxRatio_yoy  netIncome_yoy  \\\n",
       "0             0.085716                  0.064198        -0.0336   \n",
       "\n",
       "   netIncomeRatio_yoy   eps_yoy  epsdiluted_yoy  weightedAverageShsOut_yoy  \\\n",
       "0           -0.052753 -0.008117       -0.008157                  -0.025435   \n",
       "\n",
       "   weightedAverageShsOutDil_yoy symbol        date         symbol_date  \n",
       "0                     -0.025578   AAPL  2024-09-28  (AAPL, 2024-09-28)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47abcfd7-fcfc-44ee-bf39-194b62583559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Clean & align by (symbol, date)\n",
    "def clean_and_align(dfs, nan_threshold=503, keep_cols=[\"symbol\",\"date\"]):\n",
    "    \"\"\"\n",
    "    1) Drop columns with too many NaNs\n",
    "    2) Replace inf with NaN\n",
    "    3) Drop rows with any remaining NaNs\n",
    "    4) Align multiple DataFrames by shared (symbol, date) rows\n",
    "    \"\"\"\n",
    "    cleaned = {}\n",
    "    for name, df in dfs.items():\n",
    "        # Select _yoy numeric columns\n",
    "        yoy_cols = [c for c in df.select_dtypes(include=[float,int]).columns if c.endswith(\"_yoy\")]\n",
    "        # Keep only valid columns under nan_threshold\n",
    "        valid_cols = [c for c in yoy_cols if df[c].isna().sum() <= nan_threshold]\n",
    "        sub_df = df[valid_cols + keep_cols].copy()\n",
    "        \n",
    "        # Replace infs with NaN and drop rows with any remaining NaNs\n",
    "        sub_df[valid_cols] = sub_df[valid_cols].replace([np.inf, -np.inf], np.nan)\n",
    "        before = sub_df.shape[0]\n",
    "        sub_df.dropna(subset=valid_cols, inplace=True)\n",
    "        after = sub_df.shape[0]\n",
    "        print(f\"{name}: {before - after} rows dropped due to NaNs\")\n",
    "        \n",
    "        # Create composite key\n",
    "        sub_df[\"symbol_date\"] = list(zip(sub_df[\"symbol\"], sub_df[\"date\"]))\n",
    "        cleaned[name] = sub_df\n",
    "        print(f\"{name} shape after cleaning: {sub_df.shape}\")\n",
    "    \n",
    "    # Find shared (symbol, date) across all dfs\n",
    "    common_pairs = set.intersection(*(set(df[\"symbol_date\"]) for df in cleaned.values()))\n",
    "    print(f\"Shared (symbol, date) rows across all dfs: {len(common_pairs)}\")\n",
    "    \n",
    "    # Filter each df to shared rows\n",
    "    aligned = {name: df[df[\"symbol_date\"].isin(common_pairs)].copy().reset_index(drop=True) \n",
    "               for name, df in cleaned.items()}\n",
    "    \n",
    "    # Drop helper column\n",
    "    for df in aligned.values():\n",
    "        df.drop(columns=[\"symbol_date\"], inplace=True)\n",
    "    \n",
    "    return aligned, common_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae15f3d-85b7-4b9c-8dc4-9e2495ffa557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income: 504 rows dropped due to NaNs\n",
      "income shape after cleaning: (502, 18)\n",
      "balance: 504 rows dropped due to NaNs\n",
      "balance shape after cleaning: (502, 13)\n",
      "cashflow: 505 rows dropped due to NaNs\n",
      "cashflow shape after cleaning: (501, 13)\n",
      "Shared (symbol, date) rows across all dfs: 491\n"
     ]
    }
   ],
   "source": [
    "aligned, common_pairs = clean_and_align({\n",
    "    \"income\": income_growth,\n",
    "    \"balance\": balance_growth,\n",
    "    \"cashflow\": cashflow_growth\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e19ca92-8def-42bd-9773-3a774d7d9135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Run PCA on selected columns\n",
    "def run_pca(df, selected_cols, n_components=5):\n",
    "    sub_df = df[selected_cols].copy()\n",
    "    scaled = StandardScaler().fit_transform(sub_df)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pcs = pca.fit_transform(scaled)\n",
    "    pcs_df = pd.DataFrame(pcs, index=sub_df.index, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "    \n",
    "    print(f\"PCA shape: {pcs_df.shape}\")\n",
    "    print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "    return pcs_df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "512f12a1-643f-458b-ae19-f8fb82a8b909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA shape: (491, 3)\n",
      "Explained variance ratio: [0.34710423 0.34377133 0.30912445]\n",
      "PCA shape: (491, 3)\n",
      "Explained variance ratio: [0.646486  0.3168122 0.0367018]\n",
      "PCA shape: (491, 3)\n",
      "Explained variance ratio: [6.80308141e-01 3.19691688e-01 1.71405147e-07]\n"
     ]
    }
   ],
   "source": [
    "income_cols = [\"revenue_yoy\",\"netIncome_yoy\",\"operatingIncomeRatio_yoy\"]\n",
    "balance_cols = [\"totalAssets_yoy\",\"totalLiabilities_yoy\",\"totalStockholdersEquity_yoy\"]\n",
    "cashflow_cols = [\"operatingCashFlow_yoy\",\"freeCashFlow_yoy\",\"netCashProvidedByOperatingActivities_yoy\"]\n",
    "\n",
    "income_pcs, income_pca_model = run_pca(aligned[\"income\"], income_cols, n_components=3)\n",
    "balance_pcs, balance_pca_model = run_pca(aligned[\"balance\"], balance_cols, n_components=3)\n",
    "cashflow_pcs, cashflow_pca_model = run_pca(aligned[\"cashflow\"], cashflow_cols, n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae20fdcf-d30f-4470-a939-fd5ae9f0a84c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'income_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge the three PCA results on symbol/date\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_pca \u001b[38;5;241m=\u001b[39m \u001b[43mincome_pca\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(balance_pca, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m], suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_inc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_bal\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m merged_pca \u001b[38;5;241m=\u001b[39m merged_pca\u001b[38;5;241m.\u001b[39mmerge(cashflow_pca, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m], suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get only PCA columns\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'income_pca' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge the three PCA results on symbol/date\n",
    "merged_pca = income_pca.merge(balance_pca, on=[\"symbol\",\"date\"], suffixes=(\"_inc\", \"_bal\"))\n",
    "merged_pca = merged_pca.merge(cashflow_pca, on=[\"symbol\",\"date\"], suffixes=(\"\", \"_cf\"))\n",
    "\n",
    "# Get only PCA columns\n",
    "pca_cols = [c for c in merged_pca.columns if c.startswith(\"PCA\")]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_all = merged_pca[pca_cols].corr()\n",
    "\n",
    "# Display as heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_all, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Cross-Statement PCA Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0bcfb-6149-428a-b866-8e5798126426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 2. Merge with PCA DataFrame ---\n",
    "# Example: merging with income PCA; can merge balance/cashflow similarly\n",
    "merged_df = income_pca.merge(\n",
    "    price_earnings_df[[\"symbol\", \"log_PE\"]],\n",
    "    on=\"symbol\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# If you want, merge balance and cashflow PCA as well\n",
    "merged_df = merged_df.merge(balance_pca, on=[\"symbol\",\"date\"], suffixes=(\"\",\"_bal\"))\n",
    "merged_df = merged_df.merge(cashflow_pca, on=[\"symbol\",\"date\"], suffixes=(\"\",\"_cf\"))\n",
    "\n",
    "# --- 3. Preview ---\n",
    "print(merged_df.head())\n",
    "print(\"Shape of merged dataset:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ecb57-b5fa-42e7-8d83-351d68f244d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: columns in merged_df\n",
    "# 'PCA1', 'PCA1_bal', 'PCA1_cf', 'log_PE'\n",
    "\n",
    "# --- 1. Separate regressions for each PCA1 ---\n",
    "def run_ols_plot(x_col, y_col='log_PE', df=merged_df, color='blue', label=''):\n",
    "    X = sm.add_constant(df[x_col])  # add intercept\n",
    "    y = df[y_col]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(f\"OLS Regression: {y_col} ~ {x_col}\")\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Scatter + regression line\n",
    "    sns.scatterplot(x=x_col, y=y_col, data=df, color=color, alpha=0.7, label=label)\n",
    "    # Add regression line\n",
    "    x_vals = np.linspace(df[x_col].min(), df[x_col].max(), 100)\n",
    "    y_vals = model.params[0] + model.params[1]*x_vals\n",
    "    plt.plot(x_vals, y_vals, color=color, linestyle='--')\n",
    "    return model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "model_income = run_ols_plot('PCA1', color='blue', label='Income PCA1')\n",
    "model_balance = run_ols_plot('PCA1_bal', color='green', label='Balance PCA1')\n",
    "model_cashflow = run_ols_plot('PCA1_cf', color='red', label='Cashflow PCA1')\n",
    "\n",
    "plt.xlabel('PCA1 Component')\n",
    "plt.ylabel('Log(Price / Earnings)')\n",
    "plt.title('Log(PE) vs PCA1 for Each Statement with OLS Line')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Multiple regression including all three PCA1s ---\n",
    "X_multi = merged_df[['PCA1','PCA1_bal','PCA1_cf']]\n",
    "X_multi = sm.add_constant(X_multi)\n",
    "y_multi = merged_df['log_PE']\n",
    "\n",
    "multi_model = sm.OLS(y_multi, X_multi).fit()\n",
    "print(\"Multiple regression: log_PE ~ PCA1 + PCA1_bal + PCA1_cf\")\n",
    "print(multi_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61229223-2e01-45a1-be31-ff084145b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
