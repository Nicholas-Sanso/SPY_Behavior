{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9ed79e-112a-418f-b955-5c13dd46dd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from pygam import LinearGAM, s\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e00d038a-40e8-4ebd-a394-1178326e305a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from CSV cache...\n",
      "(503, 8)\n",
      "Index(['symbol', 'name', 'sector', 'subSector', 'headQuarter',\n",
      "       'dateFirstAdded', 'cik', 'founded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# --- LOAD FROM CACHE OR FETCH ---\n",
    "if os.path.exists(tickers_csv_file):\n",
    "    print(\"Loading tickers from CSV cache...\")\n",
    "    df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "else:\n",
    "    print(\"Fetching tickers from API...\")\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}\"\n",
    "    df_sp500 = pd.DataFrame(requests.get(url).json())\n",
    "\n",
    "    # Save to CSV\n",
    "    df_sp500.to_csv(tickers_csv_file, index=False)\n",
    "    print(f\"Saved {len(df_sp500)} tickers to CSV cache.\")\n",
    "\n",
    "# --- PREVIEW ---\n",
    "print(df_sp500.shape)\n",
    "print(df_sp500.columns)\n",
    "\n",
    "df_sp500.head(2)\n",
    "\n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3d2046-ea29-42a8-94a4-d33602247506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from JSON cache...\n",
      "(503, 10)\n",
      "Index(['symbol', 'date', 'revenue', 'grossProfit', 'operatingIncome',\n",
      "       'netIncome', 'eps', 'ebitda', 'costOfRevenue', 'operatingExpenses'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>grossProfit</th>\n",
       "      <th>operatingIncome</th>\n",
       "      <th>netIncome</th>\n",
       "      <th>eps</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>costOfRevenue</th>\n",
       "      <th>operatingExpenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XYZ</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>24121053000</td>\n",
       "      <td>8889036000</td>\n",
       "      <td>892327000</td>\n",
       "      <td>2897047000</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1345598000</td>\n",
       "      <td>15232017000</td>\n",
       "      <td>7996709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTD</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2444831000</td>\n",
       "      <td>1972819000</td>\n",
       "      <td>427167000</td>\n",
       "      <td>393076000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>514657000</td>\n",
       "      <td>472012000</td>\n",
       "      <td>1545652000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date      revenue  grossProfit  operatingIncome   netIncome  \\\n",
       "0    XYZ  2024-12-31  24121053000   8889036000        892327000  2897047000   \n",
       "1    TTD  2024-12-31   2444831000   1972819000        427167000   393076000   \n",
       "\n",
       "   eps      ebitda  costOfRevenue  operatingExpenses  \n",
       "0  4.7  1345598000    15232017000         7996709000  \n",
       "1  0.8   514657000      472012000         1545652000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up data folder and file paths\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "json_file = os.path.join(data_folder, \"income_statements.json\")\n",
    "\n",
    "# Define which fields to keep\n",
    "desired_fields = [\n",
    "    'symbol',\n",
    "    'date',\n",
    "    'revenue',\n",
    "    'grossProfit',\n",
    "    'operatingIncome',\n",
    "    'netIncome',\n",
    "    'eps',\n",
    "    'ebitda',\n",
    "    'costOfRevenue',\n",
    "    'operatingExpenses'\n",
    "]\n",
    "\n",
    "# Try loading from cached JSON if it exists\n",
    "if os.path.exists(json_file):\n",
    "    print(\"Loading data from JSON cache...\")\n",
    "    with open(json_file, 'r') as f:\n",
    "        records = json.load(f)\n",
    "else:\n",
    "    # Load tickers\n",
    "    df = pd.read_csv(csv_file)\n",
    "    tickers = df_sp500['symbol'].dropna().tolist()\n",
    "\n",
    "    API_KEY = 'YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6'\n",
    "    records = []\n",
    "\n",
    "    # Fetch most recent income statement per ticker\n",
    "    for ticker in tickers:\n",
    "        url = f'https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=1&apikey={API_KEY}'\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                row = data[0]\n",
    "                row['symbol'] = ticker\n",
    "                filtered_row = {k: row.get(k, None) for k in desired_fields}\n",
    "                records.append(filtered_row)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(.2)  # Rate limiting\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(\"Saved data to JSON cache.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "income_df = pd.DataFrame(records)\n",
    "\n",
    "# Show sample\n",
    "print(income_df.shape)\n",
    "print(income_df.columns)\n",
    "income_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3296f43-e2e1-4fde-903b-46bbb2743736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/income-statement_annual_limit2.json\n",
      "Saved 1006 records to /Users/nicholassanso/Desktop/Trading/Data/balance-sheet-statement_annual_limit2.json\n"
     ]
    }
   ],
   "source": [
    "def fetch_statement(endpoint, tickers, period, limit, data_folder):\n",
    "    \"\"\"Fetch statements with unique JSON filename based on endpoint, period, limit.\"\"\"\n",
    "    output_file = os.path.join(\n",
    "        data_folder,\n",
    "        f\"{endpoint}_{period}_limit{limit}.json\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        with open(output_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/{endpoint}/{ticker}?period={period}&limit={limit}&apikey={API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                for row in data:\n",
    "                    row[\"symbol\"] = ticker\n",
    "                records.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker} ({endpoint}): {e}\")\n",
    "        time.sleep(.2)  # API polite rate limit\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "income_data   = fetch_statement(\"income-statement\", tickers, \"annual\", 2, data_folder)\n",
    "balance_data  = fetch_statement(\"balance-sheet-statement\", tickers, \"annual\", 2, data_folder)\n",
    "cashflow_data = fetch_statement(\"cash-flow-statement\", tickers, \"annual\", 2, data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e02a2f-f487-4b0a-9915-1b7bb222dab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "tickers_csv_path = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# Output JSONs\n",
    "income_json = os.path.join(data_folder, \"income_statements.json\")\n",
    "balance_json = os.path.join(data_folder, \"balance_sheets.json\")\n",
    "cashflow_json = os.path.join(data_folder, \"cash_flows.json\")\n",
    "\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "\n",
    "# -------------------------\n",
    "# Helper function\n",
    "# -------------------------\n",
    "def fetch_statement(endpoint, tickers, output_file):\n",
    "    \"\"\"Fetch latest financial statement for all tickers from FMP.\"\"\"\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        with open(output_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/{endpoint}/{ticker}?limit=1&apikey={API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                row = data[0]\n",
    "                row[\"symbol\"] = ticker\n",
    "                records.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker} ({endpoint}): {e}\")\n",
    "        time.sleep(.2)  # API polite rate limit\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "    return records\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "tickers_df = pd.read_csv(tickers_csv_path)\n",
    "tickers = tickers_df[\"symbol\"].dropna().unique().tolist()\n",
    "\n",
    "# Pull each type of statement\n",
    "income_data   = fetch_statement(\"income-statement\", tickers, income_json)\n",
    "balance_data  = fetch_statement(\"balance-sheet-statement\", tickers, balance_json)\n",
    "cashflow_data = fetch_statement(\"cash-flow-statement\", tickers, cashflow_json)\n",
    "\n",
    "# Convert to DataFrames\n",
    "income_df   = pd.DataFrame(income_data)\n",
    "balance_df  = pd.DataFrame(balance_data)\n",
    "cashflow_df = pd.DataFrame(cashflow_data)\n",
    "\n",
    "print(\"Income shape:\", income_df.shape)\n",
    "print(\"Balance shape:\", balance_df.shape)\n",
    "print(\"Cash flow shape:\", cashflow_df.shape)\n",
    "\n",
    "print(income_df.columns)\n",
    "print(balance_df.columns)\n",
    "print(cashflow_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fffff96-d96e-45dc-a7d7-47616b48c94b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "tickers_csv_path = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "output_json_path = os.path.join(data_folder, \"ratios.json\")\n",
    "\n",
    "# Try loading from cache\n",
    "if os.path.exists(output_json_path):\n",
    "    print(\"Loading ratios from JSON cache...\")\n",
    "    with open(output_json_path, \"r\") as f:\n",
    "        all_ratios = json.load(f)\n",
    "else:\n",
    "    print(\"No cache found — fetching ratios from API...\")\n",
    "    tickers_df = pd.read_csv(tickers_csv_path)\n",
    "    tickers = tickers_df['symbol'].dropna().unique().tolist()\n",
    "\n",
    "    api_key = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "    base_url = \"https://financialmodelingprep.com/api/v3/ratios/{}?limit=1&apikey={}\"\n",
    "\n",
    "    all_ratios = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            url = base_url.format(ticker, api_key)\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                all_ratios.append(data[0])\n",
    "            time.sleep(.2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "\n",
    "    # Save to cache\n",
    "    with open(output_json_path, \"w\") as f:\n",
    "        json.dump(all_ratios, f, indent=2)\n",
    "    print(f\"Saved {len(all_ratios)} records to JSON cache.\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_ratios = pd.DataFrame(all_ratios)\n",
    "print(df_ratios.columns)\n",
    "print(df_ratios.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffdf80-2c08-4501-b116-0ca68b785655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Set up paths\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "csv_file    = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "json_file   = os.path.join(data_folder, \"company_info.json\")\n",
    "\n",
    "# 2. Define the fields you want to keep\n",
    "desired_fields = [\n",
    "    \"symbol\", \"companyName\", \"marketCap\", \"sector\", \"industry\", \"beta\",\n",
    "    \"price\", \"lastAnnualDividend\", \"volume\", \"exchange\", \"exchangeShortName\",\n",
    "    \"country\", \"isEtf\", \"isFund\"\n",
    "]\n",
    "\n",
    "# 3. Load or fetch company info\n",
    "records = []\n",
    "\n",
    "if os.path.exists(json_file):\n",
    "    print(\"Loading company info from JSON cache...\")\n",
    "    with open(json_file, \"r\") as f:\n",
    "        records = json.load(f)\n",
    "\n",
    "else:\n",
    "    print(\"No cache found — fetching company info from API...\")\n",
    "    df      = pd.read_csv(csv_file)\n",
    "    tickers = df['symbol'].dropna().unique().tolist()\n",
    "    print(f\"Found {len(tickers)} unique tickers.\")\n",
    "\n",
    "    API_KEY  = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "    BASE_URL = \"https://financialmodelingprep.com/api/v3/profile/{}?apikey={}\"\n",
    "\n",
    "    failed = []\n",
    "\n",
    "    for i, ticker in enumerate(tickers, 1):\n",
    "        url = BASE_URL.format(ticker, API_KEY)\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "            resp.raise_for_status()\n",
    "            data = resp.json()\n",
    "            if isinstance(data, list) and data:\n",
    "                row = data[0]\n",
    "                filtered = {k: row.get(k, None) for k in desired_fields}\n",
    "                records.append(filtered)\n",
    "            else:\n",
    "                print(f\"  • No profile data for {ticker}\")\n",
    "                failed.append(ticker)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "            failed.append(ticker)\n",
    "        time.sleep(.2)\n",
    "\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} company records to cache.\")\n",
    "    if failed:\n",
    "        print(f\"{len(failed)} tickers failed to fetch: {failed[:5]}...\")\n",
    "\n",
    "# 4. Convert to DataFrame and inspect\n",
    "company_df = pd.DataFrame(records)\n",
    "company_df.drop_duplicates(subset=\"symbol\", inplace=True)\n",
    "\n",
    "print(\"Columns returned:\", company_df.columns.tolist())\n",
    "print(company_df.columns)\n",
    "print(company_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dca5f-0a24-4546-b411-7754550467bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## --- PREP DATA ---\n",
    "# Convert to numeric\n",
    "df_ratios['priceEarningsRatio'] = pd.to_numeric(df_ratios['priceEarningsRatio'], errors='coerce')\n",
    "df_growth['growthEPSDiluted'] = pd.to_numeric(df_growth['growthEPSDiluted'], errors='coerce')\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.merge(\n",
    "    df_ratios[['symbol', 'priceEarningsRatio']],\n",
    "    df_growth[['symbol', 'growthEPSDiluted']],\n",
    "    on='symbol',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Drop missing values\n",
    "reg_df = merged_df.dropna(subset=['priceEarningsRatio', 'growthEPSDiluted']).copy()\n",
    "\n",
    "# Filter out non-positive values\n",
    "reg_df = reg_df[(reg_df['growthEPSDiluted'] > 0) & (reg_df['priceEarningsRatio'] > 0)]\n",
    "\n",
    "# Log-transform P/E\n",
    "reg_df['ln_PE'] = np.log(reg_df['priceEarningsRatio'])\n",
    "\n",
    "# --- RUN REGRESSIONS AT DIFFERENT CAPS ---\n",
    "results_table = []\n",
    "\n",
    "for cap in np.arange(0.05, 1.05, 0.05):  # 5% increments\n",
    "    temp_df = reg_df[reg_df['growthEPSDiluted'] <= cap]\n",
    "    if len(temp_df) < 5:  # skip if not enough data\n",
    "        continue\n",
    "    \n",
    "    X = sm.add_constant(temp_df['growthEPSDiluted'])\n",
    "    y = temp_df['ln_PE']\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    results_table.append({\n",
    "        'cap': cap,\n",
    "        'r2': model.rsquared,\n",
    "        't_stat': model.tvalues['growthEPSDiluted'],\n",
    "        'mse': mean_squared_error(y, model.fittedvalues),\n",
    "        'model': model\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results_table).sort_values('mse')\n",
    "\n",
    "# --- PRINT RESULTS ---\n",
    "print(results_df[['cap', 'r2', 't_stat', 'mse']])\n",
    "\n",
    "best_model_row = results_df.iloc[0]\n",
    "print(\"\\nBest growth cap:\", best_model_row['cap'])\n",
    "print(best_model_row['model'].summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c924f-93ba-46a5-8adf-fa50602b44aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(reg_df['growthEPSDiluted'], reg_df['ln_PE'], alpha=0.6, edgecolors='k')\n",
    "\n",
    "# Regression line\n",
    "x_vals = np.linspace(reg_df['growthEPSDiluted'].min(), reg_df['growthEPSDiluted'].max(), 5)\n",
    "plt.xlim(0, .3)\n",
    "y_vals = model.params['const'] + model.params['growthEPSDiluted'] * x_vals\n",
    "plt.ylim(2, 5)\n",
    "\n",
    "plt.plot(x_vals, y_vals, color='red', linewidth=2, label='OLS fit')\n",
    "\n",
    "# Labels & title\n",
    "plt.xlabel(\"EPS Growth (decimal form, e.g., 0.30 = 30%)\", fontsize=12)\n",
    "plt.ylabel(\"ln(P/E)\", fontsize=12)\n",
    "plt.title(\"Log(P/E) vs EPS Growth\", fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1aeaf9-0720-471b-b74b-2e6b7118bd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Non‐linear threshold model: allow different slopes below/above gamma\n",
    "def threshold_model(gamma):\n",
    "    reg_df['below'] = (reg_df['growthEPSDiluted'] <= gamma) * reg_df['growthEPSDiluted']\n",
    "    reg_df['above'] = (reg_df['growthEPSDiluted'] > gamma) * reg_df['growthEPSDiluted']\n",
    "    formula = 'ln_PE ~ below + above'\n",
    "    return smf.ols(formula, data=reg_df).fit()\n",
    "\n",
    "# Grid‐search gamma in [0.05,1.0]\n",
    "gammas, rss = [], []\n",
    "for g in np.linspace(0.05, 1, 20):\n",
    "    fit = threshold_model(g)\n",
    "    gammas.append(g); rss.append(sum(fit.resid**2))\n",
    "\n",
    "best_gamma = gammas[np.argmin(rss)]\n",
    "best_model   = threshold_model(best_gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24620638-a7f4-48e6-9a47-dc5b0243266c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e20657-6066-4d57-be7c-9dabc512ad14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
