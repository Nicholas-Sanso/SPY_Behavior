{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9ed79e-112a-418f-b955-5c13dd46dd65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from pygam import LinearGAM, s\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2982057a-32e3-43e6-b761-6240815efa25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tickers from CSV cache...\n",
      "(503, 8)\n",
      "Index(['symbol', 'name', 'sector', 'subSector', 'headQuarter',\n",
      "       'dateFirstAdded', 'cik', 'founded'],\n",
      "      dtype='object')\n",
      "  symbol                  name                  sector  \\\n",
      "0    XYZ           Block, Inc.              Technology   \n",
      "1    TTD  The Trade Desk, Inc.              Technology   \n",
      "2   DDOG               Datadog              Technology   \n",
      "3   COIN       Coinbase Global      Financial Services   \n",
      "4   DASH              DoorDash  Communication Services   \n",
      "\n",
      "                            subSector              headQuarter dateFirstAdded  \\\n",
      "0           Software - Infrastructure      Oakland, California     2025-07-23   \n",
      "1              Software - Application      Ventura, California     2025-07-18   \n",
      "2              Software - Application  New York City, New York     2025-07-09   \n",
      "3  Financial - Data & Stock Exchanges     Wilmington, Delaware     2025-05-19   \n",
      "4      Internet Content & Information        San Francisco, CA     2025-03-24   \n",
      "\n",
      "       cik founded  \n",
      "0  1512673    2009  \n",
      "1  1671933    2009  \n",
      "2  1561550    2010  \n",
      "3  1679788    2012  \n",
      "4  1792789    2013  \n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# --- LOAD FROM CACHE OR FETCH ---\n",
    "if os.path.exists(tickers_csv_file):\n",
    "    print(\"Loading tickers from CSV cache...\")\n",
    "    df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "else:\n",
    "    print(\"Fetching tickers from API...\")\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/sp500_constituent?apikey={API_KEY}\"\n",
    "    df_sp500 = pd.DataFrame(requests.get(url).json())\n",
    "\n",
    "    # Save to CSV\n",
    "    df_sp500.to_csv(tickers_csv_file, index=False)\n",
    "    print(f\"Saved {len(df_sp500)} tickers to CSV cache.\")\n",
    "\n",
    "    \n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()\n",
    "# --- PREVIEW ---\n",
    "print(df_sp500.shape)\n",
    "print(df_sp500.columns)\n",
    "print(df_sp500.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1844560d-77dc-4f2a-8993-96bb263662be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/income-statement_annual_limit2.json\n",
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/balance-sheet-statement_annual_limit2.json\n",
      "Loading from cache: /Users/nicholassanso/Desktop/Trading/Data/cash-flow-statement_annual_limit2.json\n",
      "Income shape: (1006, 38)\n",
      "Balance shape: (1006, 54)\n",
      "Cash flow shape: (1006, 40)\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'revenue', 'costOfRevenue',\n",
      "       'grossProfit', 'grossProfitRatio', 'researchAndDevelopmentExpenses',\n",
      "       'generalAndAdministrativeExpenses', 'sellingAndMarketingExpenses',\n",
      "       'sellingGeneralAndAdministrativeExpenses', 'otherExpenses',\n",
      "       'operatingExpenses', 'costAndExpenses', 'interestIncome',\n",
      "       'interestExpense', 'depreciationAndAmortization', 'ebitda',\n",
      "       'ebitdaratio', 'operatingIncome', 'operatingIncomeRatio',\n",
      "       'totalOtherIncomeExpensesNet', 'incomeBeforeTax',\n",
      "       'incomeBeforeTaxRatio', 'incomeTaxExpense', 'netIncome',\n",
      "       'netIncomeRatio', 'eps', 'epsdiluted', 'weightedAverageShsOut',\n",
      "       'weightedAverageShsOutDil', 'link', 'finalLink'],\n",
      "      dtype='object')\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'cashAndCashEquivalents',\n",
      "       'shortTermInvestments', 'cashAndShortTermInvestments', 'netReceivables',\n",
      "       'inventory', 'otherCurrentAssets', 'totalCurrentAssets',\n",
      "       'propertyPlantEquipmentNet', 'goodwill', 'intangibleAssets',\n",
      "       'goodwillAndIntangibleAssets', 'longTermInvestments', 'taxAssets',\n",
      "       'otherNonCurrentAssets', 'totalNonCurrentAssets', 'otherAssets',\n",
      "       'totalAssets', 'accountPayables', 'shortTermDebt', 'taxPayables',\n",
      "       'deferredRevenue', 'otherCurrentLiabilities', 'totalCurrentLiabilities',\n",
      "       'longTermDebt', 'deferredRevenueNonCurrent',\n",
      "       'deferredTaxLiabilitiesNonCurrent', 'otherNonCurrentLiabilities',\n",
      "       'totalNonCurrentLiabilities', 'otherLiabilities',\n",
      "       'capitalLeaseObligations', 'totalLiabilities', 'preferredStock',\n",
      "       'commonStock', 'retainedEarnings',\n",
      "       'accumulatedOtherComprehensiveIncomeLoss',\n",
      "       'othertotalStockholdersEquity', 'totalStockholdersEquity',\n",
      "       'totalEquity', 'totalLiabilitiesAndStockholdersEquity',\n",
      "       'minorityInterest', 'totalLiabilitiesAndTotalEquity',\n",
      "       'totalInvestments', 'totalDebt', 'netDebt', 'link', 'finalLink'],\n",
      "      dtype='object')\n",
      "Index(['date', 'symbol', 'reportedCurrency', 'cik', 'fillingDate',\n",
      "       'acceptedDate', 'calendarYear', 'period', 'netIncome',\n",
      "       'depreciationAndAmortization', 'deferredIncomeTax',\n",
      "       'stockBasedCompensation', 'changeInWorkingCapital',\n",
      "       'accountsReceivables', 'inventory', 'accountsPayables',\n",
      "       'otherWorkingCapital', 'otherNonCashItems',\n",
      "       'netCashProvidedByOperatingActivities',\n",
      "       'investmentsInPropertyPlantAndEquipment', 'acquisitionsNet',\n",
      "       'purchasesOfInvestments', 'salesMaturitiesOfInvestments',\n",
      "       'otherInvestingActivites', 'netCashUsedForInvestingActivites',\n",
      "       'debtRepayment', 'commonStockIssued', 'commonStockRepurchased',\n",
      "       'dividendsPaid', 'otherFinancingActivites',\n",
      "       'netCashUsedProvidedByFinancingActivities',\n",
      "       'effectOfForexChangesOnCash', 'netChangeInCash', 'cashAtEndOfPeriod',\n",
      "       'cashAtBeginningOfPeriod', 'operatingCashFlow', 'capitalExpenditure',\n",
      "       'freeCashFlow', 'link', 'finalLink'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def fetch_statement(endpoint, tickers, period, limit, data_folder):\n",
    "    \"\"\"Fetch statements with unique JSON filename based on endpoint, period, limit.\"\"\"\n",
    "    output_file = os.path.join(\n",
    "        data_folder,\n",
    "        f\"{endpoint}_{period}_limit{limit}.json\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        with open(output_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        url = f\"https://financialmodelingprep.com/api/v3/{endpoint}/{ticker}?period={period}&limit={limit}&apikey={API_KEY}\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            if data:\n",
    "                for row in data:\n",
    "                    row[\"symbol\"] = ticker\n",
    "                records.extend(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker} ({endpoint}): {e}\")\n",
    "        time.sleep(.2)  # API polite rate limit\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "income_data_2_years   = fetch_statement(\"income-statement\", tickers, \"annual\", 2, data_folder)\n",
    "balance_data_2_years  = fetch_statement(\"balance-sheet-statement\", tickers, \"annual\", 2, data_folder)\n",
    "cashflow_data_2_years = fetch_statement(\"cash-flow-statement\", tickers, \"annual\", 2, data_folder)\n",
    "\n",
    "# Convert to DataFrames\n",
    "income_data_2_years   = pd.DataFrame(income_data_2_years)\n",
    "balance_data_2_years  = pd.DataFrame(balance_data_2_years)\n",
    "cashflow_data_2_years = pd.DataFrame(cashflow_data_2_years)\n",
    "\n",
    "print(\"Income shape:\", income_data_2_years.shape)\n",
    "print(\"Balance shape:\", balance_data_2_years.shape)\n",
    "print(\"Cash flow shape:\", cashflow_data_2_years.shape)\n",
    "\n",
    "print(income_data_2_years.columns)\n",
    "print(balance_data_2_years.columns)\n",
    "print(cashflow_data_2_years.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb6e9e1d-7967-4d9d-bedd-c234025a3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_symbol_date(df):\n",
    "    return df.sort_values([\"symbol\", \"date\"])\n",
    "\n",
    "\n",
    "def compute_yoy_growth(df, exclude_cols=[\"symbol\", \"date\",\"link\",\"finalLink\"]):\n",
    "    numeric_cols = df.select_dtypes(include=[float, int]).columns\n",
    "    numeric_cols = [c for c in numeric_cols if c not in exclude_cols]\n",
    "    \n",
    "    df_growth = df.copy()\n",
    "    for col in numeric_cols:\n",
    "        df_growth[col + \"_yoy\"] = df.groupby(\"symbol\")[col].pct_change()\n",
    "    \n",
    "    return df_growth\n",
    "\n",
    "\n",
    "income_sorted = sort_by_symbol_date(income_data_2_years)\n",
    "balance_sorted = sort_by_symbol_date(balance_data_2_years)\n",
    "cashflow_sorted = sort_by_symbol_date(cashflow_data_2_years)\n",
    "\n",
    "income_growth = compute_yoy_growth(income_sorted)\n",
    "balance_growth = compute_yoy_growth(balance_sorted)\n",
    "cashflow_growth = compute_yoy_growth(cashflow_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130f17b0-b137-4386-b95c-58b08ed4a839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income 0/NaN counts per YoY column:\n",
      "                                             zeros  nans\n",
      "revenue_yoy                                      0   503\n",
      "grossProfit_yoy                                  0   503\n",
      "costAndExpenses_yoy                              0   503\n",
      "ebitdaratio_yoy                                  0   503\n",
      "operatingIncome_yoy                              0   503\n",
      "operatingIncomeRatio_yoy                         0   503\n",
      "incomeBeforeTax_yoy                              0   503\n",
      "incomeBeforeTaxRatio_yoy                         0   503\n",
      "netIncomeRatio_yoy                               0   503\n",
      "ebitda_yoy                                       0   504\n",
      "operatingExpenses_yoy                            0   507\n",
      "costOfRevenue_yoy                                0   510\n",
      "totalOtherIncomeExpensesNet_yoy                  0   535\n",
      "generalAndAdministrativeExpenses_yoy             0   756\n",
      "netIncome_yoy                                    1   503\n",
      "eps_yoy                                          1   503\n",
      "epsdiluted_yoy                                   1   503\n",
      "depreciationAndAmortization_yoy                  1   508\n",
      "incomeTaxExpense_yoy                             1   508\n",
      "sellingGeneralAndAdministrativeExpenses_yoy      1   530\n",
      "otherExpenses_yoy                                1   642\n",
      "researchAndDevelopmentExpenses_yoy               1   792\n",
      "sellingAndMarketingExpenses_yoy                  3   841\n",
      "interestIncome_yoy                               4   667\n",
      "weightedAverageShsOut_yoy                        7   503\n",
      "grossProfitRatio_yoy                             9   503\n",
      "weightedAverageShsOutDil_yoy                     9   503\n",
      "interestExpense_yoy                              9   530\n",
      "\n",
      "Balance 0/NaN counts per YoY column:\n",
      "                                             zeros  nans\n",
      "otherNonCurrentAssets_yoy                        0   503\n",
      "totalAssets_yoy                                  0   503\n",
      "totalLiabilities_yoy                             0   503\n",
      "totalStockholdersEquity_yoy                      0   503\n",
      "totalEquity_yoy                                  0   503\n",
      "totalLiabilitiesAndStockholdersEquity_yoy        0   503\n",
      "totalLiabilitiesAndTotalEquity_yoy               0   503\n",
      "totalNonCurrentAssets_yoy                        0   504\n",
      "totalCurrentAssets_yoy                           0   505\n",
      "longTermDebt_yoy                                 0   505\n",
      "totalNonCurrentLiabilities_yoy                   0   505\n",
      "retainedEarnings_yoy                             0   505\n",
      "otherNonCurrentLiabilities_yoy                   0   508\n",
      "netReceivables_yoy                               0   513\n",
      "accountPayables_yoy                              0   530\n",
      "shortTermInvestments_yoy                         0   780\n",
      "otherAssets_yoy                                  0   971\n",
      "otherLiabilities_yoy                             0   985\n",
      "cashAndCashEquivalents_yoy                       1   503\n",
      "cashAndShortTermInvestments_yoy                  1   503\n",
      "totalDebt_yoy                                    1   504\n",
      "totalCurrentLiabilities_yoy                      1   508\n",
      "otherCurrentLiabilities_yoy                      1   510\n",
      "propertyPlantEquipmentNet_yoy                    1   511\n",
      "otherCurrentAssets_yoy                           1   536\n",
      "othertotalStockholdersEquity_yoy                 1   547\n",
      "totalInvestments_yoy                             1   602\n",
      "longTermInvestments_yoy                          1   658\n",
      "deferredTaxLiabilitiesNonCurrent_yoy             1   665\n",
      "taxPayables_yoy                                  1   674\n",
      "deferredRevenue_yoy                              1   731\n",
      "netDebt_yoy                                      2   503\n",
      "capitalLeaseObligations_yoy                      2   605\n",
      "taxAssets_yoy                                    2   752\n",
      "inventory_yoy                                    3   666\n",
      "deferredRevenueNonCurrent_yoy                    3   869\n",
      "accumulatedOtherComprehensiveIncomeLoss_yoy      5   515\n",
      "intangibleAssets_yoy                             5   586\n",
      "shortTermDebt_yoy                                6   539\n",
      "minorityInterest_yoy                            13   719\n",
      "goodwillAndIntangibleAssets_yoy                 24   539\n",
      "preferredStock_yoy                              27   949\n",
      "goodwill_yoy                                    73   553\n",
      "commonStock_yoy                                244   534\n",
      "\n",
      "Cashflow 0/NaN counts per YoY column:\n",
      "                                              zeros  nans\n",
      "netCashProvidedByOperatingActivities_yoy          0   503\n",
      "netCashUsedForInvestingActivites_yoy              0   503\n",
      "netCashUsedProvidedByFinancingActivities_yoy      0   503\n",
      "cashAtBeginningOfPeriod_yoy                       0   503\n",
      "operatingCashFlow_yoy                             0   503\n",
      "freeCashFlow_yoy                                  0   503\n",
      "otherWorkingCapital_yoy                           0   506\n",
      "investmentsInPropertyPlantAndEquipment_yoy        0   529\n",
      "deferredIncomeTax_yoy                             0   567\n",
      "effectOfForexChangesOnCash_yoy                    0   636\n",
      "inventory_yoy                                     0   660\n",
      "purchasesOfInvestments_yoy                        0   672\n",
      "commonStockIssued_yoy                             0   791\n",
      "netIncome_yoy                                     1   503\n",
      "netChangeInCash_yoy                               1   503\n",
      "cashAtEndOfPeriod_yoy                             1   503\n",
      "depreciationAndAmortization_yoy                   1   507\n",
      "capitalExpenditure_yoy                            1   527\n",
      "accountsReceivables_yoy                           1   561\n",
      "accountsPayables_yoy                              1   574\n",
      "acquisitionsNet_yoy                               1   618\n",
      "salesMaturitiesOfInvestments_yoy                  1   665\n",
      "changeInWorkingCapital_yoy                        2   503\n",
      "otherNonCashItems_yoy                             2   504\n",
      "debtRepayment_yoy                                 2   536\n",
      "dividendsPaid_yoy                                 2   597\n",
      "otherFinancingActivites_yoy                       3   511\n",
      "otherInvestingActivites_yoy                       5   532\n",
      "stockBasedCompensation_yoy                        5   580\n",
      "commonStockRepurchased_yoy                        8   568\n"
     ]
    }
   ],
   "source": [
    "def count_zeros_nans_yoy(df):\n",
    "    # Keep only numeric columns that end with \"_yoy\"\n",
    "    numeric_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c.endswith(\"_yoy\")]\n",
    "    \n",
    "    # Count zeros and NaNs\n",
    "    zero_counts = (df[numeric_cols] == 0).sum()\n",
    "    nan_counts = df[numeric_cols].isna().sum()\n",
    "    \n",
    "    # Combine into a single DataFrame\n",
    "    summary = pd.DataFrame({\n",
    "        \"zeros\": zero_counts,\n",
    "        \"nans\": nan_counts\n",
    "    }).sort_values(by=[\"zeros\", \"nans\"], ascending=True)\n",
    "    \n",
    "    # Force full display\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "        print(summary)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "print(\"Income 0/NaN counts per YoY column:\")\n",
    "income_summary = count_zeros_nans_yoy(income_growth)\n",
    "\n",
    "print(\"\\nBalance 0/NaN counts per YoY column:\")\n",
    "balance_summary = count_zeros_nans_yoy(balance_growth)\n",
    "\n",
    "print(\"\\nCashflow 0/NaN counts per YoY column:\")\n",
    "cashflow_summary = count_zeros_nans_yoy(cashflow_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44b62e6-ec7c-4941-a1c2-1dc53084de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_pca(df, nan_threshold=505, n_components=5):\n",
    "    # 1. Keep only _yoy numeric columns\n",
    "    yoy_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c.endswith(\"_yoy\")]\n",
    "    sub_df = df[yoy_cols].copy()\n",
    "    \n",
    "    # 2. Drop columns with too many NaNs\n",
    "    valid_cols = sub_df.columns[sub_df.isna().sum() <= nan_threshold]\n",
    "    \n",
    "    # --- Print columns that made it through the NaN filter ---\n",
    "    print(f\"Columns kept (<= {nan_threshold} NaNs):\")\n",
    "    for col in valid_cols:\n",
    "        print(f\"  {col} (NaNs: {sub_df[col].isna().sum()})\")\n",
    "    \n",
    "    sub_df = sub_df[valid_cols]\n",
    "    \n",
    "    # 3. Replace infinities with NaN\n",
    "    sub_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    # 4. Drop rows with any remaining NaNs\n",
    "    sub_df.dropna(inplace=True)\n",
    "    \n",
    "    # Count how many rows are being used\n",
    "    row_count = sub_df.shape[0]\n",
    "    \n",
    "    # 5. Standardize\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(sub_df)\n",
    "    \n",
    "    # 6. Run PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pcs = pca.fit_transform(scaled)\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    pcs_df = pd.DataFrame(\n",
    "        pcs,\n",
    "        index=sub_df.index,\n",
    "        columns=[f\"PC{i+1}\" for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    return pcs_df, pca, scaler, valid_cols, row_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f285d7f8-e30d-425d-af2a-46e199b6884b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns kept (<= 503 NaNs):\n",
      "  revenue_yoy (NaNs: 503)\n",
      "  grossProfit_yoy (NaNs: 503)\n",
      "  grossProfitRatio_yoy (NaNs: 503)\n",
      "  costAndExpenses_yoy (NaNs: 503)\n",
      "  ebitdaratio_yoy (NaNs: 503)\n",
      "  operatingIncome_yoy (NaNs: 503)\n",
      "  operatingIncomeRatio_yoy (NaNs: 503)\n",
      "  incomeBeforeTax_yoy (NaNs: 503)\n",
      "  incomeBeforeTaxRatio_yoy (NaNs: 503)\n",
      "  netIncome_yoy (NaNs: 503)\n",
      "  netIncomeRatio_yoy (NaNs: 503)\n",
      "  eps_yoy (NaNs: 503)\n",
      "  epsdiluted_yoy (NaNs: 503)\n",
      "  weightedAverageShsOut_yoy (NaNs: 503)\n",
      "  weightedAverageShsOutDil_yoy (NaNs: 503)\n",
      "Columns kept (<= 503 NaNs):\n",
      "  cashAndCashEquivalents_yoy (NaNs: 503)\n",
      "  cashAndShortTermInvestments_yoy (NaNs: 503)\n",
      "  otherNonCurrentAssets_yoy (NaNs: 503)\n",
      "  totalAssets_yoy (NaNs: 503)\n",
      "  totalLiabilities_yoy (NaNs: 503)\n",
      "  totalStockholdersEquity_yoy (NaNs: 503)\n",
      "  totalEquity_yoy (NaNs: 503)\n",
      "  totalLiabilitiesAndStockholdersEquity_yoy (NaNs: 503)\n",
      "  totalLiabilitiesAndTotalEquity_yoy (NaNs: 503)\n",
      "  netDebt_yoy (NaNs: 503)\n",
      "Columns kept (<= 503 NaNs):\n",
      "  netIncome_yoy (NaNs: 503)\n",
      "  changeInWorkingCapital_yoy (NaNs: 503)\n",
      "  netCashProvidedByOperatingActivities_yoy (NaNs: 503)\n",
      "  netCashUsedForInvestingActivites_yoy (NaNs: 503)\n",
      "  netCashUsedProvidedByFinancingActivities_yoy (NaNs: 503)\n",
      "  netChangeInCash_yoy (NaNs: 503)\n",
      "  cashAtEndOfPeriod_yoy (NaNs: 503)\n",
      "  cashAtBeginningOfPeriod_yoy (NaNs: 503)\n",
      "  operatingCashFlow_yoy (NaNs: 503)\n",
      "  freeCashFlow_yoy (NaNs: 503)\n",
      "Income PCA shape: (502, 5) | Rows used: 502\n",
      "Balance PCA shape: (502, 5) | Rows used: 502\n",
      "Cashflow PCA shape: (501, 5) | Rows used: 501\n"
     ]
    }
   ],
   "source": [
    "# Run prepare_for_PCA on Income\n",
    "income_pcs, income_pca_model, income_scaler, income_used_cols, income_row_count = prepare_for_pca(\n",
    "    income_growth, nan_threshold=503, n_components=5\n",
    ")\n",
    "\n",
    "# Run prepare_for_PCA on Balance\n",
    "balance_pcs, balance_pca_model, balance_scaler, balance_used_cols, balance_row_count = prepare_for_pca(\n",
    "    balance_growth, nan_threshold=503, n_components=5\n",
    ")\n",
    "\n",
    "# Run prepare_for_PCA on Cashflow\n",
    "cashflow_pcs, cashflow_pca_model, cashflow_scaler, cashflow_used_cols, cashflow_row_count = prepare_for_pca(\n",
    "    cashflow_growth, nan_threshold=503, n_components=5\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(\"Income PCA shape:\", income_pcs.shape, \"| Rows used:\", income_row_count)\n",
    "print(\"Balance PCA shape:\", balance_pcs.shape, \"| Rows used:\", balance_row_count)\n",
    "print(\"Cashflow PCA shape:\", cashflow_pcs.shape, \"| Rows used:\", cashflow_row_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f008f3-7b3e-417f-9c03-4dc4949d06de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pe_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mX\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m X_clean \u001b[38;5;241m=\u001b[39m X[mask]\n\u001b[0;32m---> 14\u001b[0m Y_clean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mpe_series\u001b[49m\u001b[38;5;241m.\u001b[39mloc[X_clean\u001b[38;5;241m.\u001b[39mindex])  \u001b[38;5;66;03m# pe_series is your PE for each row\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Standardize\u001b[39;00m\n\u001b[1;32m     17\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pe_series' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: X = all yoy columns from income, Y = log(PE)\n",
    "yoy_cols = [c for c in income_growth.columns if c.endswith(\"_yoy\")]\n",
    "X = income_growth[yoy_cols].copy()\n",
    "\n",
    "# Make sure to drop rows with NaN or inf\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "mask = ~X.isna().any(axis=1)\n",
    "X_clean = X[mask]\n",
    "Y_clean = np.log(pe_series.loc[X_clean.index])  # pe_series is your PE for each row\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_clean)\n",
    "\n",
    "# Fit PLS\n",
    "n_components = 2\n",
    "pls = PLSRegression(n_components=n_components)\n",
    "pls.fit(X_scaled, Y_clean)\n",
    "\n",
    "# Extract factors (latent components)\n",
    "factors = pd.DataFrame(\n",
    "    pls.x_scores_,\n",
    "    columns=[f\"PLS_F{i+1}\" for i in range(n_components)],\n",
    "    index=X_clean.index\n",
    ")\n",
    "\n",
    "# Add symbol/date if needed\n",
    "factors[\"symbol\"] = income_growth.loc[X_clean.index, \"symbol\"].values\n",
    "factors[\"date\"] = income_growth.loc[X_clean.index, \"date\"].values\n",
    "\n",
    "print(\"PLS factors shape:\", factors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe41bef-cee1-4672-8647-9f96ee8348b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Income common factor\n",
    "income_factor = extract_common_factor(income_pcs, income_pca_model)\n",
    "income_factor.name = \"income_factor\"\n",
    "\n",
    "# Balance common factor\n",
    "balance_factor = extract_common_factor(balance_pcs, balance_pca_model)\n",
    "balance_factor.name = \"balance_factor\"\n",
    "\n",
    "# Cashflow common factor\n",
    "cashflow_factor = extract_common_factor(cashflow_pcs, cashflow_pca_model)\n",
    "cashflow_factor.name = \"cashflow_factor\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e99b94f6-8d3e-42fb-a8cf-ec67af3acf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common factors shape (aligned rows): (499, 5)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: get the common index across all three factors\n",
    "common_index = income_factor.index.intersection(balance_factor.index).intersection(cashflow_factor.index)\n",
    "\n",
    "# Step 2: subset each factor to only rows in common_index\n",
    "income_factor_aligned = income_factor.loc[common_index]\n",
    "balance_factor_aligned = balance_factor.loc[common_index]\n",
    "cashflow_factor_aligned = cashflow_factor.loc[common_index]\n",
    "\n",
    "# Step 3: combine into one DataFrame\n",
    "common_factors = pd.concat(\n",
    "    [income_factor_aligned, balance_factor_aligned, cashflow_factor_aligned], axis=1\n",
    ")\n",
    "common_factors.columns = [\"income_factor\", \"balance_factor\", \"cashflow_factor\"]\n",
    "\n",
    "# Step 4: add symbol/date from one of the aligned DataFrames\n",
    "common_factors[\"symbol\"] = income_growth.loc[common_index, \"symbol\"].values\n",
    "common_factors[\"date\"] = income_growth.loc[common_index, \"date\"].values\n",
    "\n",
    "print(\"Common factors shape (aligned rows):\", common_factors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e1d03-cb1d-49a2-a982-a9bb67aa104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run PCA on the 3 factors (exclude symbol/date)\n",
    "factor_cols = [\"income_factor\", \"balance_factor\", \"cashflow_factor\"]\n",
    "\n",
    "factor_pca_df, factor_var = run_pca_on_selected_yoy_clean(\n",
    "    common_factors,\n",
    "    selected_yoy_cols=factor_cols,\n",
    "    n_components=3,  # max 3 since we have 3 factors\n",
    "    keep_cols=[\"symbol\",\"date\"]\n",
    ")\n",
    "\n",
    "print(\"PCA on common factors explained variance:\", factor_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3a2ac-0bde-4951-a774-ae35f4c15a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_pca_on_selected_yoy_clean(df, selected_yoy_cols, n_components=5, keep_cols=[\"symbol\",\"date\"]):\n",
    "    \"\"\"\n",
    "    df: DataFrame with growth data (includes _yoy columns)\n",
    "    selected_yoy_cols: list of yoy column names you want to use in PCA\n",
    "    n_components: number of PCA components\n",
    "    keep_cols: reference columns to carry over (like symbol, date)\n",
    "    \"\"\"\n",
    "    # Make sure selected columns exist\n",
    "    missing = [c for c in selected_yoy_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Some selected yoy columns not found in DataFrame: {missing}\")\n",
    "    \n",
    "    # Extract the selected yoy data\n",
    "    X = df[selected_yoy_cols].copy()\n",
    "    \n",
    "    # Replace infinite with NaN\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Drop rows with any NaN in selected columns\n",
    "    mask_valid = ~X.isna().any(axis=1)\n",
    "    X_clean = X[mask_valid]\n",
    "    \n",
    "    # Keep symbol/date for those same rows\n",
    "    meta = df.loc[mask_valid, keep_cols].reset_index(drop=True)\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_clean)\n",
    "    \n",
    "    # Run PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    components = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Build PCA DataFrame\n",
    "    pca_df = pd.DataFrame(components, columns=[f\"PCA{i+1}\" for i in range(n_components)])\n",
    "    for col in keep_cols:\n",
    "        if col in meta.columns:\n",
    "            pca_df[col] = meta[col].values\n",
    "    \n",
    "    # Print info about rows used and columns included\n",
    "    print(f\"PCA shape: {pca_df.shape} | Rows used: {X_clean.shape[0]}\")\n",
    "    print(f\"Columns used for PCA: {list(X_clean.columns)}\")\n",
    "    \n",
    "    return pca_df, pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfac9dc-5a71-4800-9f8a-0818712bffbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example, pick a few yoy columns you trust\n",
    "income_cols = [\"revenue_yoy\",\"netIncome_yoy\",\"ebitda_yoy\",\"operatingIncome_yoy\"]\n",
    "balance_cols = [\"totalAssets_yoy\",\"totalLiabilities_yoy\",\"totalStockholdersEquity_yoy\"]\n",
    "cashflow_cols = [\"operatingCashFlow_yoy\",\"freeCashFlow_yoy\",\"netCashProvidedByOperatingActivities_yoy\"]\n",
    "\n",
    "income_pca, income_var = run_pca_on_selected_yoy_clean(income_growth, income_cols, n_components=3)\n",
    "balance_pca, balance_var = run_pca_on_selected_yoy_clean(balance_growth, balance_cols, n_components=3)\n",
    "cashflow_pca, cashflow_var = run_pca_on_selected_yoy_clean(cashflow_growth, cashflow_cols, n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ce4d0-9fa5-441e-bcfc-07d52a2b0b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Explained variance ratio:\", income_var)\n",
    "print(\"Total explained variance:\", income_var.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20fdcf-d30f-4470-a939-fd5ae9f0a84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge the three PCA results on symbol/date\n",
    "merged_pca = income_pca.merge(balance_pca, on=[\"symbol\",\"date\"], suffixes=(\"_inc\", \"_bal\"))\n",
    "merged_pca = merged_pca.merge(cashflow_pca, on=[\"symbol\",\"date\"], suffixes=(\"\", \"_cf\"))\n",
    "\n",
    "# Get only PCA columns\n",
    "pca_cols = [c for c in merged_pca.columns if c.startswith(\"PCA\")]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_all = merged_pca[pca_cols].corr()\n",
    "\n",
    "# Display as heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_all, annot=False, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Cross-Statement PCA Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c6059-704c-487f-87a5-bb5743fd38d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "API_KEY = \"YwnbHRjcJvf6Md2OPoKbSRGHlzZ7hjR6\"\n",
    "data_folder = os.path.join(os.path.expanduser(\"~/Desktop/Trading\"), \"Data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "tickers_csv_file = os.path.join(data_folder, \"sp500_tickers.csv\")\n",
    "\n",
    "# Load tickers\n",
    "df_sp500 = pd.read_csv(tickers_csv_file)\n",
    "tickers = df_sp500[\"symbol\"].dropna().unique().tolist()\n",
    "\n",
    "# Output file\n",
    "output_file = os.path.join(data_folder, \"price_and_earnings.json\")\n",
    "\n",
    "def fetch_price_and_earnings(tickers, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Loading from cache: {output_file}\")\n",
    "        return pd.DataFrame(json.load(open(output_file)))\n",
    "\n",
    "    records = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Get current price\n",
    "            quote_url = f\"https://financialmodelingprep.com/api/v3/quote/{ticker}?apikey={API_KEY}\"\n",
    "            price_data = requests.get(quote_url).json()\n",
    "            if not price_data:\n",
    "                continue\n",
    "            price = price_data[0][\"price\"]\n",
    "\n",
    "            # Get latest annual income statement (EPS or netIncome)\n",
    "            income_url = f\"https://financialmodelingprep.com/api/v3/income-statement/{ticker}?limit=1&apikey={API_KEY}\"\n",
    "            income_data = requests.get(income_url).json()\n",
    "            if not income_data:\n",
    "                continue\n",
    "            eps = income_data[0].get(\"eps\")\n",
    "            net_income = income_data[0].get(\"netIncome\")\n",
    "\n",
    "            records.append({\n",
    "                \"symbol\": ticker,\n",
    "                \"price\": price,\n",
    "                \"eps\": eps,\n",
    "                \"netIncome\": net_income\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "        time.sleep(0.2)  # polite rate limit\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "    print(f\"Saved {len(records)} records to {output_file}\")\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Fetch or load\n",
    "price_earnings_df = fetch_price_and_earnings(tickers, output_file)\n",
    "print(price_earnings_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2823c-6caf-4c64-85c8-041878f9a826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute log(PE)\n",
    "price_earnings_df = price_earnings_df.copy()\n",
    "price_earnings_df = price_earnings_df[price_earnings_df[\"eps\"] > 0]  # remove zero or negative EPS\n",
    "price_earnings_df[\"log_PE\"] = np.log(price_earnings_df[\"price\"] / price_earnings_df[\"eps\"])\n",
    "\n",
    "# Print row count\n",
    "print(\"Number of rows after filtering EPS > 0:\", len(price_earnings_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d0bcfb-6149-428a-b866-8e5798126426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 2. Merge with PCA DataFrame ---\n",
    "# Example: merging with income PCA; can merge balance/cashflow similarly\n",
    "merged_df = income_pca.merge(\n",
    "    price_earnings_df[[\"symbol\", \"log_PE\"]],\n",
    "    on=\"symbol\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# If you want, merge balance and cashflow PCA as well\n",
    "merged_df = merged_df.merge(balance_pca, on=[\"symbol\",\"date\"], suffixes=(\"\",\"_bal\"))\n",
    "merged_df = merged_df.merge(cashflow_pca, on=[\"symbol\",\"date\"], suffixes=(\"\",\"_cf\"))\n",
    "\n",
    "# --- 3. Preview ---\n",
    "print(merged_df.head())\n",
    "print(\"Shape of merged dataset:\", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ecb57-b5fa-42e7-8d83-351d68f244d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: columns in merged_df\n",
    "# 'PCA1', 'PCA1_bal', 'PCA1_cf', 'log_PE'\n",
    "\n",
    "# --- 1. Separate regressions for each PCA1 ---\n",
    "def run_ols_plot(x_col, y_col='log_PE', df=merged_df, color='blue', label=''):\n",
    "    X = sm.add_constant(df[x_col])  # add intercept\n",
    "    y = df[y_col]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(f\"OLS Regression: {y_col} ~ {x_col}\")\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Scatter + regression line\n",
    "    sns.scatterplot(x=x_col, y=y_col, data=df, color=color, alpha=0.7, label=label)\n",
    "    # Add regression line\n",
    "    x_vals = np.linspace(df[x_col].min(), df[x_col].max(), 100)\n",
    "    y_vals = model.params[0] + model.params[1]*x_vals\n",
    "    plt.plot(x_vals, y_vals, color=color, linestyle='--')\n",
    "    return model\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "model_income = run_ols_plot('PCA1', color='blue', label='Income PCA1')\n",
    "model_balance = run_ols_plot('PCA1_bal', color='green', label='Balance PCA1')\n",
    "model_cashflow = run_ols_plot('PCA1_cf', color='red', label='Cashflow PCA1')\n",
    "\n",
    "plt.xlabel('PCA1 Component')\n",
    "plt.ylabel('Log(Price / Earnings)')\n",
    "plt.title('Log(PE) vs PCA1 for Each Statement with OLS Line')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Multiple regression including all three PCA1s ---\n",
    "X_multi = merged_df[['PCA1','PCA1_bal','PCA1_cf']]\n",
    "X_multi = sm.add_constant(X_multi)\n",
    "y_multi = merged_df['log_PE']\n",
    "\n",
    "multi_model = sm.OLS(y_multi, X_multi).fit()\n",
    "print(\"Multiple regression: log_PE ~ PCA1 + PCA1_bal + PCA1_cf\")\n",
    "print(multi_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61229223-2e01-45a1-be31-ff084145b6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
